## Bá»™ Ä‘á» 1

---

### Q1. 
A company is developing an application in the AWS Cloud. The application's HTTP API contains critical information that is published in Amazon API Gateway. The critical information must be accessible from only a limited set of trusted IP addresses that belong to the company's internal network.

Which solution will meet these requirements?
- Set up an API Gateway private integration to restrict access to a predefined set of IP addresses.
- Create a resource policy for the API that denies access to any IP address that is not specifically allowed.
- Directly deploy the API in a private subnet. Create a network ACL. Set up rules to allow the traffic from specific IP addresses.
- Modify the security group that is attached to API Gateway to allow inbound traffic from only the trusted IP addresses.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

Company phÃ¡t triá»ƒn application vá»›i HTTP API trong API Gateway

Chá»‰ muá»‘n cho phÃ©p truy cáº­p tá»« danh sÃ¡ch IP giá»›i háº¡n (limited set of trusted IP addresses) thuá»™c máº¡ng ná»™i bá»™ cÃ´ng ty (company's internal network)

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Create a resource policy for the API that denies access to any IP address that is not specifically allowed.

![img](https://static.cloudexam.pro/courses/5/1756734464759-qbwgf5fe-CleanShot_2025-09-01_at_22.47.32.png)

â†’ Resource Policy cÅ©ng lÃ  má»™t cÃ¡ch khÃ´ng máº¥t tiá»n Ä‘á»ƒ Ä‘á»‹nh nghÄ©a quyá»n kiá»ƒm soÃ¡t truy cáº­p API Gateway theo IP. Policy cÃ³ thá»ƒ Ä‘á»‹nh nghÄ©a chÃ­nh xÃ¡c cÃ¡c IP Ä‘Æ°á»£c phÃ©p vÃ  tá»« chá»‘i táº¥t cáº£ IP khÃ¡c. ÄÃ¢y lÃ  best practice cho IP whitelisting trong API Gateway.

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Set up an API Gateway private integration to restrict access to a predefined set of IP addresses.

â†’ Sai. Private integration chá»‰ lÃ  cÆ¡ cháº¿ cho phÃ©p API Gateway káº¿t ná»‘i vá»›i backend services trong VPC, khÃ´ng liÃªn quan Ä‘áº¿n viá»‡c kiá»ƒm soÃ¡t client access theo IP.

âŒ Directly deploy the API in a private subnet. Create a network ACL. Set up rules to allow the traffic from specific IP addresses.

â†’ Sai. API Gateway lÃ  managed service, vá» báº£n cháº¥t khÃ´ng thá»ƒ deploy trá»±c tiáº¿p trong subnet cá»§a VPC. Do Ä‘Ã³ Network ACL cÅ©ng khÃ´ng Ã¡p dá»¥ng cho API Gateway.

âŒ Modify the security group that is attached to API Gateway to allow inbound traffic from only the trusted IP addresses.

â†’ Sai. API Gateway khÃ´ng sá»­ dá»¥ng security groups nhÆ° EC2. Security groups khÃ´ng Ã¡p dá»¥ng cho managed services nhÆ° API Gateway.

ğŸ”‘ Tips and tricks:

API Gateway access control theo IP thÃ¬ cÃ³ thá»ƒ sá»­ dá»¥ng resource policy hoáº·c

API Gateway lÃ  managed service nÃªn khÃ´ng thá»ƒ Ä‘áº·t bÃªn trong subnet VPC. Ká»ƒ cáº£ Private REST APIs thÃ¬ cÅ©ng chá»‰ lÃ  cÆ¡ cháº¿ cho phÃ©p access Ä‘áº¿n API Gateway thÃ´ng qua endpoint tá»« VPC, chá»© khÃ´ng pháº£i báº£n thÃ¢n API GW Ä‘Æ°á»£c Ä‘áº·t trong VPC
</details>

---

### Q2. 
A company needs to give a globally distributed development team secure access to the company's AWS resources in a way that complies with security policies.

The company currently uses an on-premises Active Directory for internal authentication. The company uses AWS Organizations to manage multiple AWS accounts that support multiple projects.

The company needs a solution to integrate with the existing infrastructure to provide centralized identity management and access control.

Which solution will meet these requirements with the LEAST operational overhead?

- Set up AWS Directory Service to create an AWS managed Microsoft Active Directory on AWS. Establish a trust relationship with the on-premises Active Directory. Use IAM rotes that are assigned to Active Directory groups to access AWS resources within the company's AWS accounts.
- Create an IAM user for each developer. Manually manage permissions for each IAM user based on each user's involvement with each project. Enforce multi-factor authentication (MFA) as an additional layer of security.
- Use AD Connector in AWS Directory Service to connect to the on-premises Active Directory. Integrate AD Connector with AWS IAM Identity Center. Configure permissions sets to give each AD group access to specific AWS accounts and resources.
- Use Amazon Cognito to deploy an identity federation solution. Integrate the identity federation solution with the on-premises Active Directory. Use Amazon Cognito to provide access tokens for developers to access AWS accounts and resources.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

CÃ´ng ty cáº§n cáº¥p quyá»n truy cáº­p vÃ o mÃ´i trÆ°á»ng AWS cho team dev, cá»¥ thá»ƒ lÃ  cÃ¡c AWS accounts hiá»‡n Ä‘ang Ä‘Æ°á»£c quáº£n lÃ­ bá»Ÿi AWS Organizations

ÄÃ£ cÃ³ on-premises Active Directory Ä‘á»ƒ xÃ¡c thá»±c há»‡ thá»‘ng ná»™i bá»™

Cáº§n tÃ­ch há»£p vá»›i háº¡ táº§ng hiá»‡n cÃ³ (existing infrastructure), á»Ÿ Ä‘Ã¢y cÃ³ nghÄ©a lÃ  sá»­ dá»¥ng Active Directory cÃ³ sáºµn Ä‘á»ƒ quáº£n lÃ½ xÃ¡c thá»±c táº­p trung

YÃªu cáº§u: Ã­t tá»‘n cÃ´ng nháº¥t (LEAST operational overhead)

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Use AD Connector in AWS Directory Service to connect to the on-premises Active Directory. Integrate AD Connector with AWS IAM Identity Center. Configure permissions sets to give each AD group access to specific AWS accounts and resources.

AD Connector cho phÃ©p káº¿t ná»‘i trá»±c tiáº¿p vá»›i AD hiá»‡n cÃ³ mÃ  khÃ´ng cáº§n táº¡o má»›i (integrate with the existing infrastructure)

IAM Identity Center (trÆ°á»›c Ä‘Ã¢y lÃ  AWS SSO) cung cáº¥p quáº£n lÃ½ quyá»n truy cáº­p táº­p trung cho multiple AWS accounts

Permission sets cho phÃ©p gÃ¡n quyá»n theo nhÃ³m AD, phÃ¹ há»£p vá»›i Organizations structure

ÄÃ¢y lÃ  kiáº¿n trÃºc tá»‘n Ã­t operational overhead nháº¥t vÃ¬ táº­n dá»¥ng AD hiá»‡n cÃ³ + tá»± Ä‘á»™ng sync

Kiáº¿n trÃºc:
![img](https://static.cloudexam.pro/courses/5/1756737277149-vcqaesq6-CleanShot_2025-09-01_at_23.33.17.png)

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Set up AWS Directory Service to create an AWS managed Microsoft Active Directory on AWS. Establish a trust relationship with the on-premises Active Directory. Use IAM rotes that are assigned to Active Directory groups to access AWS resources within the company's AWS accounts.

â†’ Táº¡o thÃªm má»™t AD má»›i trÃªn AWS, tÄƒng complexity vÃ  operational overhead khÃ´ng cáº§n thiáº¿t, khÃ´ng táº­n dung Ä‘Æ°á»£c infrastructure hiá»‡n táº¡i

âŒ Create an IAM user for each developer. Manually manage permissions for each IAM user based on each user's involvement with each project. Enforce multi-factor authentication (MFA) as an additional layer of security.

â†’ Táº¡o thá»§ cÃ´ng tá»«ng IAM user cho má»—i ngÆ°á»i developmer sáº½ bá»‹ operational overhead ráº¥t cao, khÃ´ng cÃ³ kháº£ nÄƒng scale hiá»‡u quáº£

âŒ Use Amazon Cognito to deploy an identity federation solution. Integrate the identity federation solution with the on-premises Active Directory. Use Amazon Cognito to provide access tokens for developers to access AWS accounts and resources.

â†’ Cognito chá»§ yáº¿u sá»­ dá»¥ng cho web applications, khÃ´ng phÃ¹ há»£p cho cáº¥p quyá»n truy cáº­p Ä‘áº¿n AWS Organizations

ğŸ”‘ Tips and tricks:

Khi cÃ¢u há»i nháº¯c Ä‘áº¿n viá»‡c liÃªn káº¿t ngÆ°á»i dÃ¹ng Active Directory Ä‘á»ƒ cho phÃ©p truy cáº­p account trong Organization thÃ¬ thÆ°á»ng nghÄ© ngay Ä‘áº¿n IAM Identity Center
</details>

---

### Q3. 
A company is hosting a website behind multiple Application Load Balancers. The company has different distribution rights for its content around the world. A solutions architect needs to ensure that users are served the correct content without violating distribution rights.

Which configuration should the solutions architect choose to meet these requirements?
- Configure Amazon CloudFront with AWS WAF
- Configure Amazon Route 53 with a geoproximity routing policy
- Configure Application Load Balancers with AWS WAF
- Configure Amazon Route 53 with a geolocation policy

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

CÃ´ng ty sá»­ dá»¥ng nhiá»u Application Load Balancers Ä‘á»ƒ host website

CÃ´ng ty cÃ³ quyá»n phÃ¢n phá»‘i ná»™i dung khÃ¡c nhau (different distribution rights) theo tá»«ng vÃ¹ng trÃªn tháº¿ giá»›i

Cáº§n Ä‘áº£m báº£o users Ä‘Æ°á»£c phá»¥c vá»¥ ná»™i dung Ä‘Ãºng mÃ  khÃ´ng vi pháº¡m quyá»n phÃ¢n phá»‘i

TÃ³m láº¡i: Cáº§n giá»›i háº¡n quyá»n truy cáº­p cá»§a user theo vÃ¹ng hoáº·c quá»‘c gia

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Configure Amazon Route 53 with a geolocation policy

Route 53 geolocation policy cho phÃ©p Ä‘á»‹nh tuyáº¿n traffic dá»±a trÃªn vá»‹ trÃ­ Ä‘á»‹a lÃ½ cá»§a user

CÃ³ thá»ƒ chá»‰ Ä‘á»‹nh chÃ­nh xÃ¡c user tá»« quá»‘c gia/chÃ¢u lá»¥c nÃ o Ä‘Æ°á»£c truy cáº­p vÃ o endpoint nÃ o

Tá»« Ä‘Ã³ giÃºp Ä‘áº£m báº£o tuÃ¢n thá»§ distribution rights báº±ng cÃ¡ch kiá»ƒm soÃ¡t truy cáº­p theo Ä‘á»‹a lÃ½

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Configure Amazon CloudFront with AWS WAF

CloudFront lÃ  CDN Ä‘á»ƒ cache vÃ  tÄƒng tá»‘c, WAF lÃ  firewall báº£o máº­t

KhÃ´ng cÃ³ kháº£ nÄƒng kiá»ƒm soÃ¡t phÃ¢n phá»‘i ná»™i dung theo quyá»n Ä‘á»‹a lÃ½ cá»¥ thá»ƒ

Máº·c dÃ¹ WAF cÃ³ kháº£ nÄƒng háº¡n cháº¿ IP theo quá»‘c gia, tuy nhiÃªn bÃ i toÃ¡n cÃ³ nhiá»u load balancer trÃªn nhiá»u nÆ¡i khÃ¡c nhau, do Ä‘Ã³ má»—i load balancer sáº½ cáº§n 1 WAF khÃ¡c nhau Ä‘á»ƒ quáº£n lÃ­, tá»« Ä‘Ã³ tá»‘n cÃ´ng sá»©c vÃ  tá»‘n thÃªm nhiá»u chi phÃ­ so vá»›i viá»‡c routing thÃ´ng qua Route53

âŒ Configure Application Load Balancers with AWS WAF

ALB + WAF chá»‰ cÃ³ thá»ƒ block/allow traffic dá»±a trÃªn rules, khÃ´ng cÃ³ kháº£ nÄƒng routing theo Ä‘á»‹a lÃ½

KhÃ´ng giáº£i quyáº¿t Ä‘Æ°á»£c yÃªu cáº§u phÃ¢n phá»‘i ná»™i dung khÃ¡c nhau theo vÃ¹ng

âŒ Configure Amazon Route 53 with a geoproximity routing policy

Geoproximity routing phá»©c táº¡p hÆ¡n, chá»§ yáº¿u dÃ¹ng Ä‘á»ƒ Ä‘iá»u chá»‰nh traffic Ä‘áº¿n server cÃ³ kháº£ nÄƒng xá»­ lÃ½ thuáº­n tiá»‡n hÆ¡n hÆ¡n báº¥t ká»ƒ vá»‹ trÃ­ cá»§a ngÆ°á»i dÃ¹ng. VÃ­ dá»¥ cÃ³ server to á»Ÿ Má»¹, server nhá» á»Ÿ ChÃ¢u Ã‚u thÃ¬ váº«n cÃ³ má»™t pháº§n ngÆ°á» dÃ¹ng ChÃ¢u Ã‚u sáº½ Ä‘Æ°á»£c Ä‘iá»u hÆ°á»›ng sang Má»¹ vÃ¬ server bÃªn Ä‘Ã³ cÃ³ táº£i tá»‘t hÆ¡n. Tá»©c lÃ  sáº½ routing theo vá»‹ trÃ­ cá»§a resource chá»© khÃ´ng pháº£i vá»‹ trÃ­ cá»§a ngÆ°á»i dÃ¹ng.

KhÃ´ng kiá»ƒm soÃ¡t Ä‘Æ°á»£c quyá»n truy cáº­p theo Ä‘á»‹a lÃ½ nhÆ° geolocation policy

ğŸ”‘ Tips and tricks:

Há»‡ thá»‘ng global cáº§n háº¡n cháº¿ quyá»n truy cáº­p theo khu vá»±c hoáº·c quá»‘c gia, cÃ³ thá»ƒ nghÄ© Ä‘áº¿n Route53 Geolocation Routing Policy
</details>

---

### Q4. 
A company runs an application in a private subnet behind an Application Load Balancer (ALB) in a VPC. The VPC has a NAT gateway and an internet gateway. The application calls the Amazon S3 API to store objects.

According to the company's security policy, traffic from the application must not travel across the internet.

Which solution will meet these requirements MOST cost-effectively?
- Configure an S3 interface endpoint. Create a security group that allows outbound traffic to Amazon S3.
- Configure an S3 gateway endpoint. Update the VPC route table to use the endpoint.
- Configure an S3 bucket policy to allow traffic from the Elastic IP address that is assigned to the NAT gateway.
- Create a second NAT gateway in the same subnet where the legacy application is deployed. Update the VPC route table to use the second NAT gateway.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

á»¨ng dá»¥ng cháº¡y trong private subnet vá»›i ALB, hiá»‡n Ä‘ang káº¿t ná»‘i Ä‘áº¿n S3

VPC cÃ³ NAT gateway vÃ  internet gateway

á»¨ng dá»¥ng cáº§n gá»i Amazon S3 API Ä‘á»ƒ lÆ°u objects mÃ  traffic khÃ´ng Ä‘Æ°á»£c Ä‘i qua internet

YÃªu cáº§u: giáº£i phÃ¡p cost-effective nháº¥t

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Configure an S3 gateway endpoint. Update the VPC route table to use the endpoint.

Gateway endpoint cho S3 lÃ  dá»‹ch vá»¥ miá»…n phÃ­, cho phÃ©p káº¿t ná»‘i Ä‘áº¿n S3 vá»›i traffic Ä‘i trá»±c tiáº¿p trong Ä‘Æ°á»ng truyá»n ná»™i bá»™ cá»§a AWS, khÃ´ng qua internet. Muá»‘n cho cÃ¡c resource trong private subnet truy cáº­p Ä‘áº¿n S3 thÃ¬ chá»‰ cáº§n cáº­p nháº­t route table Ä‘á»ƒ Ä‘iá»u hÆ°á»›ng traffic S3 qua endpoint nÃ y lÃ  sáº½ Ä‘áº¡t Ä‘Æ°á»£c yÃªu cáº§u bÃ i toÃ¡n

![img](https://static.cloudexam.pro/courses/5/1756825332440-3ncwvmv3-image.png)

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Configure an S3 interface endpoint. Create a security group that allows outbound traffic to Amazon S3.

â†’ Solution há»£p lá»‡, tuy nhiÃªn sá»­ dá»¥ng Interface endpoint sáº½ bá»‹ tÃ­nh phÃ­ theo giá» vÃ  phÃ­ data processing, Ä‘áº¯t hÆ¡n gateway endpoint, do Ä‘Ã³ khÃ´ng cáº§n thiáº¿t á»Ÿ Ä‘Ã¢y

âŒ Configure an S3 bucket policy to allow traffic from the Elastic IP address that is assigned to the NAT gateway.

â†’ Traffic váº«n pháº£i Ä‘i qua NAT gateway â†’ internet, vi pháº¡m security policy

âŒ Create a second NAT gateway in the same subnet where the legacy application is deployed. Update the VPC route table to use the second NAT gateway.

â†’ ThÃªm chi phÃ­ NAT gateway khÃ´ng cáº§n thiáº¿t vÃ  traffic váº«n Ä‘i qua internet

ğŸ”‘ Tips and tricks:

Access Ä‘áº¿n cÃ¡c service tá»« bÃªn trong VPC mÃ  khÃ´ng Ä‘i qua internet, nghÄ© ngay Ä‘áº¿n Gateway Endpoint (Ã¡p dá»¥ng cho S3, DynamoDB)
</details>

---

### Q5. 
A company's image-hosting website gives users around the world the ability to up load, view, and download images from their mobile devices. The company currently hosts the static website in an Amazon S3 bucket.

Because of the website's growing popularity, the website's performance has decreased. Users have reported latency issues when they upload and download images.

The company must improve the performance of the website.

Which solution will meet these requirements with the LEAST implementation effort?
- Configure an Amazon CloudFront distribution for the S3 bucket to improve the download performance. Enable S3 Transfer Acceleration to improve the upload performance.
- Configure Amazon EC2 instances of the right sizes in multiple AWS Regions. Migrate the application to the EC2 instances. Use an Application Load Balancer to distribute the website traffic equally among the EC2 instances. Configure AWS Global Accelerator to address global demand with low latency.
- Configure an Amazon CloudFront distribution that uses the S3 bucket as an origin to improve the download performance. Configure the application to use CloudFront to upload images to improve the upload performance. Create S3 buckets in multiple AWS Regions. Configure replication rules for the buckets to replicate users' data based on the users' location. Redirect downloads to the S3 bucket that is closest to each user's location.
- Configure AWS Global Accelerator for the S3 bucket to improve network performance. Create an endpoint for the application to use Global Accelerator instead of the S3 bucket.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

CÃ´ng ty host web tÄ©nh (static website) trÃªn S3 bucket

Users trÃªn toÃ n tháº¿ giá»›i (around the world) upload, view, download áº£nh

Users bÃ¡o cÃ¡o Ä‘á»™ trá»… (latency issues) khi upload vÃ  download

Cáº§n cáº£i thiá»‡n hiá»‡u suáº¥t vá»›i Ã­t effort nháº¥t (LEAST implementation effort)

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Configure an Amazon CloudFront distribution for the S3 bucket to improve the download performance. Enable S3 Transfer Acceleration to improve the upload performance.

BÃ i toÃ¡n Ä‘ang gáº·p váº¥n Ä‘á» á»Ÿ Ä‘á»™ trá»… khi load vÃ  upload, Ä‘á»ƒ giáº£i quyáº¿t thÃ¬ sáº½ cáº§n:

CloudFront lÃ  CDN service, cho phÃ©p cache cÃ¡c loáº¡i data nhÆ° content tÄ©nh á»Ÿ Ä‘iá»ƒm cung cáº¥p dá»‹ch vá»¥ gáº§n vá»›i ngÆ°á»i dÃ¹ng nháº¥t (edge locations), tá»« Ä‘Ã³ giÃºp giáº£m Ä‘á»™ trá»…, giÃºp cho viá»‡c load cÃ¡c content nÃ y nhanh hÆ¡n

S3 Transfer Acceleration lÃ  má»™t tÃ­nh nÄƒng cá»§a S3 cho phÃ©p upload báº±ng cÃ¡ch route traffic Ä‘áº¿n edge location, tá»« Ä‘Ã³ Ä‘i qua máº¡ng ná»™i bá»™ cá»§a AWS, giÃºp giáº£m Ä‘á»™ trá»…

Ãt effort nháº¥t: cáº£ 2 cÃ¡i á»Ÿ trÃªn Ä‘á»u lÃ  Managed service / tÃ­nh nÄƒng cÃ³ sáºµn dá»… config Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c yÃªu cáº§u, tá»‘n Ã­t effort

![img](https://static.cloudexam.pro/courses/5/1756826475250-hh7xt4wx-image.png)


CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Configure Amazon EC2 instances of the right sizes in multiple AWS Regions. Migrate the application to the EC2 instances. Use an Application Load Balancer to distribute the website traffic equally among the EC2 instances. Configure AWS Global Accelerator to address global demand with low latency.

â†’ YÃªu cáº§u migrate toÃ n bá»™ application, effort ráº¥t lá»›n, khÃ´ng phÃ¹ há»£p yÃªu cáº§u "LEAST implementation effort"

âŒ Configure an Amazon CloudFront distribution that uses the S3 bucket as an origin to improve the download performance. Configure the application to use CloudFront to upload images to improve the upload performance. Create S3 buckets in multiple AWS Regions. Configure replication rules for the buckets to replicate users' data based on the users' location. Redirect downloads to the S3 bucket that is closest to each user's location.

â†’ Solution vá»›i Ä‘á»™ phá»©c táº¡p quÃ¡ má»©c khÃ´ng cáº§n thiáº¿t: nhiá»u components, replication rules, redirect logic -> tá»‘n effort

âŒ Configure AWS Global Accelerator for the S3 bucket to improve network performance. Create an endpoint for the application to use Global Accelerator instead of the S3 bucket.

â†’ Global Accelerator máº·c dÃ¹ giÃºp giáº£m Ä‘á»™ trá»…, tÄƒng tá»‘c káº¿t ná»‘i tuy nhiÃªn khÃ´ng trá»±c tiáº¿p support S3, chá»§ yáº¿u sá»­ dá»¥ng cho ALB/NLB/EC2 endpoints

ğŸ”‘ Tips and tricks:

CÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n web tÄ©nh, content tÄ©nh mÃ  cáº§n tá»‘i Æ°u hoÃ¡ Ä‘á»™ trá»… hay tÄƒng tá»‘c upload thÃ¬ thÆ°á»ng sáº½ nghÄ© Ä‘áº¿n CloudFront, S3 Transfer Acceleration
</details>

---

### Q6. 
A digital image processing company wants to migrate its on-premises monolithic application to the AWS Cloud. The company processes thousands of images and generates large files as part of the processing workflow.

The company needs a solution to manage the growing number of image processing jobs. The solution must also reduce the manual tasks in the image processing workflow. The company does not want to manage the underlying infrastructure of the solution.

Which solution will meet these requirements with the LEAST operational overhead?
- Use Amazon Elastic Container Service (Amazon ECS) with Amazon EC2 Spot Instances to process the images. Configure Amazon Simple Queue Service (Amazon SQS) to orchestrate the workflow. Store the processed files in Amazon Elastic File System (Amazon EFS).
- Use AWS Lambda functions and Amazon EC2 Spot Instances to process the images. Store the processed files in Amazon FSx.
- Use AWS Batch jobs to process the images. Use AWS Step Functions to orchestrate the workflow. Store the processed files in an Amazon S3 bucket.
- Deploy a group of Amazon EC2 instances to process the images. Use AWS Step Functions to orchestrate the workflow. Store the processed files in an Amazon Elastic Block Store (Amazon EBS) volume.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

CÃ´ng ty xá»­ lÃ½ áº£nh muá»‘n di chuyá»ƒn há»‡ thá»‘ng tá»« on-premises lÃªn AWS Cloud

Cáº§n solution cho viá»‡c cháº¡y vÃ  quáº£n lÃ½ workflow bao gá»“m nhiá»u job xá»­ lÃ­ áº£nh sao cho Ã­t thao tÃ¡c thá»§ cÃ´ng nháº¥t vÃ  khÃ´ng muá»‘n quáº£n lÃ­ infastructure

YÃªu cáº§u: Giáº£i phÃ¡p vá»›i chi phÃ­ váº­n hÃ nh tháº¥p nháº¥t

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Use AWS Batch jobs to process the images. Use AWS Step Functions to orchestrate the workflow. Store the processed files in an Amazon S3 bucket.

AWS Batch lÃ  managed service cho phÃ©p tá»± Ä‘á»™ng hoÃ¡ vÃ  scale cÃ¡c cÃ´ng viá»‡c cháº¡y job trÃªn AWS, cho phÃ©p developer táº­p trung vÃ o viá»‡c thá»±c thi job mÃ  khÃ´ng pháº£i quáº£n lÃ½ toÃ n bá»™ cÆ¡ sá»Ÿ háº¡ táº§ng. Do Ä‘Ã³ AWS Batch sáº½ phÃ¹ há»£p vá»›i job xá»­ lÃ­ áº£nh cá»§a bÃ i toÃ¡n á»Ÿ Ä‘Ã¢y.

Step Functions lÃ  serverless service giÃºp Ä‘iá»u phá»‘i & tá»± Ä‘á»™ng hoÃ¡, cho phÃ©p build cÃ¡c luá»“ng cÃ´ng viá»‡c (workflow) phá»©c táº¡p káº¿t há»£p nhiá»u service khÃ¡c nhau, tá»« Ä‘Ã³ giÃºp giáº£m cÃ¡c tÃ¡c vá»¥ & thao tÃ¡c thá»§ cÃ´ng. Trong bÃ i toÃ¡n hiá»‡n táº¡i cÃ³ thá»ƒ sá»­ dá»¥ng Step Functions Ä‘á»ƒ Ä‘iá»u phá»‘i cÃ¡c job cá»§a AWS Batch, táº¡o ra má»™t luá»“ng xá»­ lÃ­ tá»± Ä‘á»™ng hoÃ¡ hoÃ n toÃ n.

S3 lÃ  giáº£i phÃ¡p lÆ°u trá»¯ giÃ¡ ráº», ráº¥t phÃ¹ há»£p Ä‘á»ƒ lÆ°u trá»¯ áº£nh sau khi Ä‘Ã£ xá»­ lÃ­ xong.

Tá»•ng thá»ƒ giáº£i phÃ¡p nÃ y Ä‘em láº¡i chi phÃ­ váº­n hÃ nh tháº¥p nháº¥t vÃ¬ sá»­ dá»¥ng háº§u háº¿t cÃ¡c service serverless.

Kiáº¿n trÃºc tham kháº£o:
![img](https://static.cloudexam.pro/courses/5/1756828230479-xd5expuo-image.png)

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Use Amazon Elastic Container Service (Amazon ECS) with Amazon EC2 Spot Instances to process the images. Configure Amazon Simple Queue Service (Amazon SQS) to orchestrate the workflow. Store the processed files in Amazon Elastic File System (Amazon EFS).

Solution sá»­ dá»¥ng EC2, do Ä‘Ã³ váº«n tá»‘n effort váº­n hÃ nh

âŒ Use AWS Lambda functions and Amazon EC2 Spot Instances to process the images. Store the processed files in Amazon FSx.

TÆ°Æ¡ng tá»± nhÆ° trÃªn, váº«n lÃ  solution sá»­ dá»¥ng EC2, do Ä‘Ã³ váº«n tá»‘n effort váº­n hÃ nh

âŒ Deploy a group of Amazon EC2 instances to process the images. Use AWS Step Functions to orchestrate the workflow. Store the processed files in an Amazon Elastic Block Store (Amazon EBS) volume.

TÆ°Æ¡ng tá»± nhÆ° trÃªn, váº«n lÃ  solution sá»­ dá»¥ng EC2, do Ä‘Ã³ váº«n tá»‘n effort váº­n hÃ nh

ğŸ”‘ Tips and tricks:

Xuáº¥t hiá»‡n keyword Workflow thÃ¬ thÆ°á»ng sáº½ nghÄ© Ä‘áº¿n Step Functions

Solution cáº§n Ã­t effort váº­n hÃ nh thÃ¬ cÃ¡c Ä‘Ã¡p Ã¡n sáº½ khÃ´ng Æ°u tiÃªn chá»n EC2

CÃ¡c yÃªu cáº§u vá» cháº¡y job mÃ  tá»‘n Ã­t effort thÃ¬ thÆ°á»ng sáº½ nghÄ© Ä‘áº¿n cÃ¡c service nhÆ° Lambda, ECS Fargate, AWS Batch
</details>

---

### Q7. 
A company wants to provide users with access to AWS resources. The company has 1,500 users and manages their access to on-premises resources through Active Directory user groups on the corporate network. However, the company does not want users to have to maintain another identity to access the resources. A solutions architect must manage user access to the AWS resources while preserving access to the on-premises resources.

What should the solutions architect do to meet these requirements?

- Configure Security Assertion Markup Language (SAML) 2.0-based federation. Create roles with the appropriate policies attached. Map the roles to the Active Directory groups.
- Create an IAM user for each user in the company. Attach the appropriate policies to each user.
- Use Amazon Cognito with an Active Directory user pool. Create roles with the appropriate policies attached.
- Define cross-account roles with the appropriate policies attached. Map the roles to the Active Directory groups.


<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

CÃ´ng ty cÃ³ 1,500 users Ä‘ang dÃ¹ng Active Directory Ä‘á»ƒ quáº£n lÃ½ truy cáº­p á»Ÿ phÃ­a on-premises

Muá»‘n cáº¥p quyá»n cho cÃ¡c user nÃ y truy cáº­p vÃ o mÃ´i trÆ°á»ng AWS

KhÃ´ng muá»‘n dÃ¹ng thÃªm solution vá» quáº£n lÃ­ identity má»›i, mÃ  váº«n pháº£i Ä‘áº£m báº£o quyá»n to on-premises resources

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Configure Security Assertion Markup Language (SAML) 2.0-based federation. Create roles with the appropriate policies attached. Map the roles to the Active Directory groups.

SAML federation cho phÃ©p cÃ¡c ngÆ°á»i dÃ¹ng hiá»‡n táº¡i sá»­ dá»¥ng trá»±c tiáº¿p credentials cá»§a Active Directory Ä‘á»ƒ truy cáº­p vÃ o mÃ´i trÆ°á»ng AWS mÃ  khÃ´ng cáº§n má»™t cÆ¡ cháº¿ quáº£n lÃ­ identity má»›i (cháº³ng háº¡n nhÆ° IAM). Viá»‡c cáº¥p quyá»n cho cÃ¡c ngÆ°á»i dÃ¹ng nÃ y sáº½ thÃ´ng qua mapping roles vá»›i AD groups giÃºp quáº£n lÃ½ permissions hiá»‡u quáº£ cho 1,500 users.

![img](https://static.cloudexam.pro/courses/5/1756906624538-wwje5hdn-image.png)

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Create an IAM user for each user in the company. Attach the appropriate policies to each user.

â†’ Táº¡o 1,500 IAM users riÃªng biá»‡t vi pháº¡m yÃªu cáº§u "khÃ´ng quáº£n lÃ½ thÃªm identity" vÃ¬ nhÆ° tháº¿ sáº½ pháº£i quáº£n lÃ½ thÃªm IAM User Credentials.

âŒ Use Amazon Cognito with an Active Directory user pool. Create roles with the appropriate policies attached.
â†’ Cognito User Pool vá»«a táº¡o ra thÃªm má»™t identity store riÃªng biá»‡t, vi pháº¡m yÃªu cáº§u "khÃ´ng quáº£n lÃ½ thÃªm identity", hÆ¡n ná»¯a khÃ´ng tÆ°Æ¡ng tÃ¡c vÃ  liÃªn káº¿t trá»±c tiáº¿p vá»›i Active Directory hiá»‡n táº¡i Ä‘Æ°á»£c.

âŒ Define cross-account roles with the appropriate policies attached. Map the roles to the Active Directory groups.

â†’ Cross-account roles dÃ¹ng cho viá»‡c access giá»¯a cÃ¡c AWS accounts khÃ¡c nhau, khÃ´ng giáº£i quyáº¿t viá»‡c integrate vá»›i on-premises Active Directory.

ğŸ”‘ Tips and tricks:

Äá»ƒ cho phÃ©p cÃ¡c user trong Active Directory cÃ³ thá»ƒ access mÃ´i trÆ°á»ng aws cá»§a má»™t account Ä‘Æ¡n láº», khÃ´ng pháº£i AWS Organizations thÃ¬ sáº½ nghÄ© Ä‘áº¿n liÃªn káº¿t SAML 2.0 & IAM Role

ğŸ“– Reference:

https://aws.amazon.com/blogs/security/enabling-federation-to-aws-using-windows-active-directory-adfs-and-saml-2-0/
</details>

---

### Q8. 
A company has a three-tier web application that processes orders from customers. The web tier consists of Amazon EC2 instances behind an Application Load Balancer. The processing tier consists of EC2 instances. The company decoupled the web tier and processing tier by using Amazon Simple Queue Service (Amazon SQS). The storage layer uses Amazon DynamoDB.

At peak times, some users report order processing delays and halls. The company has noticed that during these delays, the EC2 instances are running at 100% CPU usage, and the SQS queue fills up. The peak times are variable and unpredictable.

The company needs to improve the performance of the application.

Which solution will meet these requirements?
- Use scheduled scaling for Amazon EC2 Auto Scaling
- Use Amazon ElastiCache for Redis in front of the DynamoDB
- Add an Amazon CloudFront distribution to cache responses for the web tier
- Use an Amazon EC2 Auto Scaling target tracking policy to scale out the processing tier instances. Use the ApproximateNumberOfMessages attribute to determine when to scale.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

BÃ i toÃ¡n cÃ³ há»‡ thá»‘ng xá»­ lÃ½ order báº±ng kiáº¿n trÃºc : Web tier (EC2 + ALB) â†’ SQS queue â†’ Processing tier (EC2) â†’ DynamoDB

Há»‡ thá»‘ng cÃ³ váº¥n Ä‘á» khi gáº·p traffic khÃ´ng dá»± Ä‘oÃ¡n Ä‘Æ°á»£c (variable and unpredictable):

EC2 processing tier cháº¡y 100% CPU

SQS queue fills up (nhiá»u message mÃ  khÃ´ng xá»­ lÃ½ háº¿t)

Users nháº­n tháº¥y viá»‡c xá»­ lÃ­ order bá»‹ delays

Cáº§n cáº£i thiá»‡n performance

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Use an Amazon EC2 Auto Scaling target tracking policy to scale out the processing tier instances. Use the ApproximateNumberOfMessages attribute to determine when to scale.

CÃ³ thá»ƒ tháº¥y há»‡ thá»‘ng hiá»‡n táº¡i Ä‘ang bá»‹ bottle neck á»Ÿ viá»‡c EC2 Processing Tier khÃ´ng xá»­ lÃ­ háº¿t data trong queue do chÆ°a cÃ³ cÆ¡ cháº¿ scale, do Ä‘Ã³ sáº½ cáº§n implement Auto Scaling Group. Káº¿t há»£p setup Target tracking policy Ä‘á»ƒ cÃ³ thá»ƒ tá»± Ä‘á»™ng scale EC2 dá»±a trÃªn metric

ApproximateNumberOfMessages - metric thá»ƒ hiá»‡n sá»‘ lÆ°á»£ng message Ä‘ang cÃ³ trong queue. Tá»©c lÃ  cÃ ng nhiá»u message thÃ¬ sáº½ scale cÃ ng nhiá»u EC2. Do Ä‘Ã³ Ä‘Ã¢y lÃ  Ä‘Ã¡p Ã¡n há»£p lÃ½, cÃ³ thá»ƒ scale Ä‘Ã¡p á»©ng Ä‘Æ°á»£c cáº£ traffic tháº¥t thÆ°á»ng (unpredictable peaks). CÃ³ thá»ƒ xem kiáº¿n trÃºc bÃªn dá»©oi Ä‘á»ƒ tháº¥y trÆ°á»›c & sau khi cáº£i thiá»‡n.

![img](https://static.cloudexam.pro/courses/5/1756908848631-bu3e2r5r-CleanShot_2025-09-03_at_23.13.19_2x.png)

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Use scheduled scaling for Amazon EC2 Auto Scaling

Do traffic tháº¥t thÆ°á»ng "variable and unpredictable" nÃªn sáº½ khÃ´ng thá»ƒ sá»­ dá»¥ng schedule scaling (scale theo lá»‹ch cá»‘ Ä‘á»‹nh) Ä‘Æ°á»£c

âŒ Use Amazon ElastiCache for Redis in front of the DynamoDB

Sai vÃ¬ bottleneck khÃ´ng pháº£i á»Ÿ DynamoDB mÃ  á»Ÿ processing tier (EC2 100% CPU + SQS fills up)

âŒ Add an Amazon CloudFront distribution to cache responses for the web tier

Sai vÃ¬ váº¥n Ä‘á» khÃ´ng pháº£i á»Ÿ web tier mÃ  á»Ÿ processing tier khÃ´ng ká»‹p xá»­ lÃ½ queue

ğŸ”‘ Tips and tricks:

Khi bÃ i toÃ¡n cÃ³ EC2 xá»­ lÃ­ SQS mÃ  gáº·p váº¥n Ä‘á» bottleneck thÃ¬ nghÄ© Ä‘áº¿n viá»‡c sá»­ dá»¥ng káº¿t há»£p Auto Scaling Group vÃ  scale dá»±a trÃªn metric sá»‘ lÆ°á»£ng message cÃ³ trong queue

Viá»‡c scale EC2 thÃ¬ thÆ°á»ng sáº½ sá»­ dá»¥ng Target Tracking policy vÃ¬ cÃ³ tÃ­nh tá»± Ä‘á»™ng hoÃ¡ cao, giÃºp Ä‘Ã¡p á»©ng khi gáº·p traffic lá»›n hoáº·c tháº¥t thÆ°á»ng

ğŸ“– Reference:

https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-using-sqs-queue.html
</details>

---

### Q9. 
A company hosts an application in a private subnet behind an Application Load Balancer. The company has already integrated the application with Amazon Cognito. The company uses an Amazon Cognito user pool to authenticate users.

The company needs to modify the application so the authenticated users can securely store their documents in an Amazon S3 bucket via the application.

Which combination of steps will securely integrate Amazon S3 with the application? (Choose two.)
- Use the existing Amazon Cognito user pool to generate Amazon S3 access tokens for users when they successfully log in.
- Create a NAT gateway in the VPC where the company hosts the application. Assign a policy to the S3 bucket to deny any request that is not initiated from Amazon Cognito.
- Create an Amazon S3 VPC endpoint in the same VPC where the company hosts the application.
- Attach a policy to the S3 bucket that allows access only from the users' IP addresses.
- Create an Amazon Cognito identity pool to generate secure Amazon S3 access tokens for users when they successfully log in.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

Há»‡ thá»‘ng host trong private subnet

CÃ³ sá»­ dá»¥ng Amazon Cognito user pool Ä‘á»ƒ xÃ¡c thá»±c users

Há»‡ thá»‘ng cáº§n cho phÃ©p ngÆ°á»i dÃ¹ng Ä‘Ã£ xÃ¡c thá»±c cÃ³ thá»ƒ káº¿t ná»‘i Ä‘áº¿n S3 má»™t cÃ¡ch an toÃ n thÃ´ng qua application

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Create an Amazon Cognito identity pool to generate secure Amazon S3 access tokens for users when they successfully log in.

Identity pool lÃ  service giÃºp táº¡o credentials táº¡m thá»i cho cÃ¡c user bÃªn ngoÃ i cÃ³ thá»ƒ truy cáº­p vÃ o mÃ´i trÆ°á»ng AWS, cÃ³ thá»ƒ sá»­ dá»¥ng Ä‘á»ƒ truy cáº­p Ä‘áº¿n S3

Create an Amazon S3 VPC endpoint in the same VPC where the company hosts the application.

Do ngÆ°á»i dÃ¹ng access Ä‘áº¿n S3 thÃ´ng qua application, do Ä‘Ã³ application sáº½ cáº§n cÆ¡ cháº¿ Ä‘á»ƒ access Ä‘áº¿n S3 má»™t cÃ¡ch an toÃ n, do Ä‘Ã³ sáº½ sá»­ dá»¥ng S3 VPC Endpoint - service cho phÃ©p application tá»« bÃªn trong VPC cÃ³ thá»ƒ access Ä‘áº¿n S3 thÃ´ng qua Ä‘Æ°á»ng truyá»n ná»™i bá»™ cá»§a AWS mÃ  khÃ´ng Ä‘i qua internet, do Ä‘Ã³ sáº½ cÃ³ tÃ­nh an toÃ n

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Use the existing Amazon Cognito user pool to generate Amazon S3 access tokens for users when they successfully log in.

User pool chá»‰ dÃ¹ng Ä‘á»ƒ xÃ¡c thá»±c, khÃ´ng thá»ƒ táº¡o AWS access tokens Ä‘á»ƒ truy cáº­p S3

âŒ Create a NAT gateway in the VPC where the company hosts the application. Assign a policy to the S3 bucket to deny any request that is not initiated from Amazon Cognito.

NAT gateway khÃ´ng cáº§n thiáº¿t khi cÃ³ sá»­ dá»¥ng VPC endpoint, hÆ¡n ná»¯a traffic sáº½ Ä‘i ra internet nÃªn sáº½ khÃ´ng an toÃ n (not secured)

âŒ Attach a policy to the S3 bucket that allows access only from the users' IP addresses.

IP addresses cá»§a users cÃ³ thá»ƒ thay Ä‘á»•i vÃ  khÃ´ng thá»ƒ biáº¿t trÆ°á»›c Ä‘Æ°á»£c, do Ä‘Ã³ Ä‘Ã¢y khÃ´ng pháº£i giáº£i phÃ¡p cÃ³ tÃ­nh má»Ÿ rá»™ng (scalable) vÃ  an toÃ n (secure)

ğŸ”‘ Tips and tricks:

Äá»ƒ cáº¥p quyá»n cho cÃ¡c user bÃªn ngoÃ i há»‡ thá»‘ng cÃ³ thá»ƒ truy cáº­p cÃ¡c AWS Service thÃ¬ nghÄ© Ä‘áº¿n Cognito Identity Pool

Cho phÃ©p application trong VPC access Ä‘áº¿n cÃ¡c service khÃ¡c má»™t cÃ¡ch an toÃ n thÃ¬ nghÄ© Ä‘áº¿n VPC Endpoint
</details>

### Q10. 
A company runs multiple workloads on virtual machines (VMs) in an on-premises data center. The company is expanding rapidly. The on-premises data center is not able to scale fast enough to meet business needs. The company wants to migrate the workloads to AWS.

The migration is time sensitive. The company wants to use a lift-and-shift strategy for non-critical workloads.

Which combination of steps will meet these requirements? (Choose three.)?
- Use AWS Application Migration Service. Install the AWS Replication Agent on the VMs.
- Use the AWS Schema Conversion Tool (AWS SCT) to collect data about the VMs.
- Use AWS App2Container (A2C) to collect data about the VMs.
- Complete the initial replication of the VMs. Launch test instances to perform acceptance tests on the VMs.
- Stop all operations on the VMs. Launch a cutover instance.
- Use AWS Database Migration Service (AWS DMS) to migrate the VMs.

<details>
<summary>Answer</summary>
TÃ³m táº¯t Ä‘á»: 

Company cáº§n migrate nhiá»u workloads tá»« VMs á»Ÿ phÃ­a on-premises lÃªn AWS vá»›i chiáº¿n thuáº­t
lift-and-shift strategy(di chuyá»ƒn nguyÃªn tráº¡ng).

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Applicaiton Migration Service (MGN) lÃ  service cho phÃ©p thá»±c hiá»‡n migrate server tá»« on-premise lÃªn AWS thÃ´ng qua hÃ¬nh thá»©c lift-and-shift. CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng cá»§a MGN thÃ¬ nhÆ° kiáº¿n trÃºc bÃªn dÆ°á»›i.

1. Thá»±c hiá»‡n cÃ i AWS Replication Agent vá» cÃ¡c server á»Ÿ phÃ­a on-premise. CÃ¡c agent nÃ y sáº½ Ä‘á»“ng bá»™ toÃ n bá»™ data cá»§a server lÃªn AWS.

2. LÃºc nÃ y trÃªn AWS sáº½ xuáº¥t hiá»‡n server trung gian gá»i lÃ  Replication server, sáº½ chá»©a cÃ¡c data Ä‘Æ°á»£c Ä‘á»“ng bá»™ tá»« phÃ­a on-premise lÃªn. Sau khi Ä‘á»“ng bá»™ xong thÃ¬ cÃ³ thá»ƒ táº¡o ra EC2 gá»i lÃ  Test Instance. Instance nÃ y sáº½ chá»©a má»i data cá»§a server on-premise, cÃ³ thá»ƒ nÃ³i lÃ  giá»‘ng há»‡t. Viá»‡c nÃ y cho phÃ©p ta test xem quÃ¡ trÃ¬nh migrate cÃ³ váº¥n Ä‘á» gÃ¬ hay khÃ´ng.

3. Sau khi test xong rá»“i thÃ¬ cÃ³ thá»ƒ xoÃ¡ server á»Ÿ phÃ­a on-premise, thá»±c hiá»‡n step Cutover - táº¡o ra instance cuá»‘i Ä‘á»ƒ káº¿t thÃºc quÃ¡ trÃ¬nh migrate.

Dá»±a vÃ o kiáº¿n trÃºc á»Ÿ trÃªn, thÃ¬ cÃ³ 3 Ä‘Ã¡p Ã¡n tÆ°Æ¡ng á»©ng vá»›i 3 step á»Ÿ trÃªn, láº§n lÆ°á»£t lÃ 

Use AWS Application Migration Service. Install the AWS Replication Agent on the VMs.

Complete the initial replication of the VMs. Launch test instances to perform acceptance tests on the VMs.

Stop all operations on the VMs. Launch a cutover instance.

âŒ CÃ¡c Ä‘Ã¡p Ã¡n sai:
âŒ Use the AWS Schema Conversion Tool (AWS SCT) to collect data about the VMs.

â†’ AWS SCT dÃ¹ng cho use case migrate database, khÃ´ng dÃ¹ng cho migrate server (VMWare)

âŒ Use AWS App2Container (A2C) to collect data about the VMs.

â†’ A2C dÃ¹ng Ä‘á»ƒ containerize applications (chuyá»ƒn thÃ nh containers), khÃ´ng pháº£i migration lift-and-shift

âŒ Use AWS Database Migration Service (AWS DMS) to migrate the VMs.

â†’ DMS chuyÃªn migrate databases, khÃ´ng dÃ¹ng cho migrate server (VMWare)

ğŸ”‘ Tips and tricks:

Nháº¯c Ä‘áº¿n viá»‡c migrate lift-and-shift hay migrate server nÃ³i chung thÃ¬ thÆ°á»ng sáº½ nghÄ© Ä‘áº¿n Application Migration Service (MGN)

ğŸ“– Reference:

https://docs.aws.amazon.com/mgn/latest/ug/what-is-application-migration-service.html
</details>

---

### Q11. 
A company runs an environment where data is stored in an Amazon S3 bucket. The objects are accessed frequently throughout the day. The company has strict data encryption requirements for data that is stored in the S3 bucket. The company currently uses AWS Key Management Service (AWS KMS) for encryption.

The company wants to optimize costs associated with encrypting S3 objects without making additional calls to AWS KMS.

Which solution will meet these requirements?
- Use server-side encryption with Amazon S3 managed keys (SSE-S3).
- Use server-side encryption with customer-provided keys (SSE-C) stored in AWS KMS.
- Use an S3 Bucket Key for server-side encryption with AWS KMS keys (SSE-KMS) on the new objects.
- Use client-side encryption with AWS KMS customer managed keys.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

Dá»¯ liá»‡u lÆ°u trong S3 bucket, Ä‘Æ°á»£c truy cáº­p thÆ°á»ng xuyÃªn trong ngÃ y (frequently throughout the day)

Hiá»‡n táº¡i Ä‘ang dÃ¹ng AWS KMS Ä‘á»ƒ mÃ£ hÃ³a

Muá»‘n tá»‘i Æ°u chi phÃ­ mÃ£ hÃ³a KMS (optimize costs) mÃ  khÃ´ng gá»i thÃªm API Call Ä‘áº¿n AWS KMS (without making additional calls to AWS KMS)

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Use an S3 Bucket Key for server-side encryption with AWS KMS keys (SSE-KMS) on the new objects.

S3 Bucket Key giáº£m chi phÃ­ AWS KMS báº±ng cÃ¡ch táº¡o má»™t key duy nháº¥t sá»­ dá»¥ng chung cho toÃ n bá»™ bucket, thay vÃ¬ táº¡o riÃªng cho tá»«ng object (hÃ nh vi máº·c Ä‘á»‹nh).

Äiá»u nÃ y giáº£m Ä‘Ã¡ng ká»ƒ sá»‘ lÆ°á»£ng API calls Ä‘áº¿n KMS (cÃ³ thá»ƒ giáº£m Ä‘áº¿n 99%), tá»« Ä‘Ã³ giáº£m chi phÃ­ mÃ  váº«n Ä‘áº£m báº£o má»©c Ä‘á»™ báº£o máº­t cao vá»›i KMS.

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Use server-side encryption with Amazon S3 managed keys (SSE-S3).

â†’ Máº·c dÃ¹ miá»…n phÃ­ nhÆ°ng khÃ´ng Ä‘Ã¡p á»©ng yÃªu cáº§u "strict encryption requirements" do khÃ´ng cÃ³ kháº£ nÄƒng kiá»ƒm soÃ¡t key.

âŒ Use client-side encryption with AWS KMS customer managed keys.

â†’ Váº«n pháº£i gá»i KMS cho má»—i thao tÃ¡c trÃªn S3, khÃ´ng giáº£m Ä‘Æ°á»£c chi phÃ­. HÆ¡n ná»¯a cÃ²n pháº£i quáº£n lÃ½ encryption/decryption á»Ÿ phÃ­a client.

âŒ Use server-side encryption with customer-provided keys (SSE-C) stored in AWS KMS.

â†’ SSE-C yÃªu cáº§u cung cáº¥p key trong má»—i request, khÃ´ng lÆ°u key trong KMS Ä‘Æ°á»£c. MÃ¢u thuáº«n vá»›i thiáº¿t káº¿ hiá»‡n táº¡i dÃ¹ng KMS.

ğŸ“– Reference:

https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-key.html
</details>

---

### Q12. 
A company hosts a website analytics application on a single Amazon EC2 On-Demand Instance. The analytics application is highly resilient and is designed to run in stateless mode.

The company notices that the application is showing signs of performance degradation during busy times and is presenting 5xx errors. The company needs to make the application scale seamlessly.

Which solution will meet these requirements MOST cost-effectively?
- Create an Amazon Machine Image (AMI) of the web application. Use the AMI to launch a second EC2 On-Demand Instance. Use an Application Load Balancer to distribute the load across the two EC2 instances.
- Create an Amazon Machine Image (AMI) of the web application. Apply the AMI to a launch template. Create an Auto Scaling group that includes the launch template. Configure the launch template to use a Spot Fleet. Attach an Application Load Balancer to the Auto Scaling group.
- Create an Amazon Machine Image (AMI) of the web application. Use the AMI to launch a second EC2 On-Demand Instance. Use Amazon Route 53 weighted routing to distribute the load across the two EC2 instances
- Create an AWS Lambda function to stop the EC2 instance and change the instance type. Create an Amazon CloudWatch alarm to invoke the Lambda function when CPU utilization is more than 75%.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

á»¨ng dá»¥ng analytics hiá»‡n táº¡i cháº¡y trÃªn 1 EC2 On-Demand instance duy nháº¥t

á»¨ng dá»¥ng stateless (tá»©c lÃ  khÃ´ng chá»©a data) vÃ  cÃ³ kháº£ nÄƒng chá»‹u lá»—i cao (highly resilient)

Gáº·p váº¥n Ä‘á» performance vÃ  5xx errors khi cáº§n xá»­ lÃ½ nhiá»u

Cáº§n cÆ¡ cháº¿ scale vÃ  tiáº¿t kiá»‡m chi phÃ­ (cost-effective)

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Create an Amazon Machine Image (AMI) of the web application. Apply the AMI to a launch template. Create an Auto Scaling group that includes the launch template. Configure the launch template to use a Spot Fleet. Attach an Application Load Balancer to the Auto Scaling group.

CÃ³ thá»ƒ tháº¥y ngay application Ä‘ang cháº¡y trÃªn 1 EC2 duy nháº¥t, do Ä‘Ã³ Ä‘á»ƒ scale Ä‘Æ°á»£c thÃ¬ cáº§n sá»­ dá»¥ng Auto Scaling group

Loáº¡i instance sáº½ lá»±a chá»n lÃ  Spot Fleet Ä‘á»ƒ giÃºp tiáº¿t kiá»‡m chi phÃ­ Ä‘áº¿n 90% so vá»›i On-Demand, máº·c dÃ¹ cÃ³ tÃ­nh báº¥t á»•n, cÃ³ thá»ƒ bá»‹ thu há»“i báº¥t cá»© lÃºc nÃ o nhÆ°ng application stateless vÃ  cÃ³ kháº£ nÄƒng chá»‹u lá»—i cao (highly resilient) nÃªn sáº½ khÃ´ng áº£nh hÆ°á»Ÿng nhiá»u

Sá»­ dá»¥ng Application Load Balancer Ä‘á»ƒ phÃ¢n phá»‘i traffic Ä‘á»u vÃ  health check

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Create an Amazon Machine Image (AMI) of the web application. Use the AMI to launch a second EC2 On-Demand Instance. Use an Application Load Balancer to distribute the load across the two EC2 instances.

KhÃ´ng scale Ä‘Æ°á»£c do chá»‰ fix cá»©ng 2 instances

âŒ Create an Amazon Machine Image (AMI) of the web application. Use the AMI to launch a second EC2 On-Demand Instance. Use Amazon Route 53 weighted routing to distribute the load across the two EC2 instances

TÆ°Æ¡ng tá»± nhÆ° trÃªn, khÃ´ng scale Ä‘Æ°á»£c do chá»‰ fix cá»©ng 2 instances

âŒ Create an AWS Lambda function to stop the EC2 instance and change the instance type. Create an Amazon CloudWatch alarm to invoke the Lambda function when CPU utilization is more than 75%.

DÃ¹ng Lambda tÄƒng thÃªm tÃ­nh phá»©c táº¡p khÃ´ng cáº§n thiáº¿t cho viá»‡c scale EC2, do Ä‘Ã³ khÃ´ng phÃ¹ há»£p. Sá»­ dá»¥ng Auto Scaling group sáº½ váº«n lÃ  sá»± lá»±a chá»n há»£p lÃ­ hÆ¡n

ğŸ”‘ Tips and tricks:

Vá»›i cÃ¡c application stateless vÃ  cÃ³ kháº£ nÄƒng chá»‹u lá»—i tá»‘t mÃ  cáº§n cÆ¡ cháº¿ scale thÃ¬ thÆ°á»ng sáº½ nghÄ© Ä‘áº¿n Auto Scaling Group & Spot Instances
</details>

---

### Q13. 
A medical company wants to perform transformations on a large amount of clinical trial data that comes from several customers. The company must extract the data from a relational database that contains the customer data. Then the company will transform the data by using a series of complex rules. The company will load the data to Amazon S3 when the transformations are complete.

All data must be encrypted where it is processed before the company stores the data in Amazon S3. All data must be encrypted by using customer-specific keys.

Which solution will meet these requirements with the LEAST amount of operational effort?

- Create one AWS Glue job for each customer. Attach a security configuration to each job that uses client-side encryption with AWS KMS managed keys (CSE-KMS) to encrypt the data.
- Create one AWS Glue job for each customer. Attach a security configuration to each job that uses server-side encryption with Amazon S3 managed keys (SSE-S3) to encrypt the data.
- Create one Amazon EMR cluster for each customer. Attach a security configuration to each cluster that uses client-side encryption with a custom client-side root key (CSE-Custom) to encrypt the data.
- Create one Amazon EMR cluster for each customer. Attach a security configuration to each cluster that uses server-side encryption with AWS KMS keys (SSE-KMS) to encrypt the data.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

CÃ´ng ty y táº¿ cáº§n xá»­ lÃ½ dá»¯ liá»‡u thá»­ nghiá»‡m lÃ¢m sÃ ng (clinical trial data) lá»›n Ä‘áº¿n tá»« nhiá»u khÃ¡ch hÃ ng

Quy trÃ¬nh: Extract tá»« relational database â†’ Transform báº±ng complex rules â†’ Load vÃ o Amazon S3

YÃªu cáº§u: mÃ£ hÃ³a táº¥t cáº£ dá»¯ liá»‡u trong quÃ¡ trÃ¬nh xá»­ lÃ½ trÆ°á»›c khi lÆ°u S3

MÃ£ hÃ³a báº±ng key do customer chá»‰ Ä‘á»‹nh (customer-specific keys)

Cáº§n giáº£i phÃ¡p tá»‘n Ã­t cÃ´ng sá»©c nháº¥t (LEAST operational effort)

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Create one AWS Glue job for each customer. Attach a security configuration to each job that uses client-side encryption with AWS KMS managed keys (CSE-KMS) to encrypt the data.

AWS Glue lÃ  dá»‹ch vá»¥ ETL serverless, phÃ¹ há»£p cho viá»‡c extract-transform-load vá»›i Ã­t effort nháº¥t. Sá»­ dá»¥ng Glue sáº½ phÃ¹ há»£p cho bÃ i toÃ¡n vÃ¬ cÃ³ kháº£ nÄƒng kÃ©o data tá»« RDS vá» xá»­ lÃ½, chuyá»ƒn Ä‘á»•i rá»“i sau Ä‘Ã³ náº¡p vÃ o S3.

CSE-KMS cho phÃ©p sá»­ dá»¥ng key do customer chá»‰ Ä‘á»‹nh (customer-specific keys) thÃ´ng qua KMS, Ä‘Ã¡p á»©ng yÃªu cáº§u mÃ£ hÃ³a riÃªng biá»‡t cho tá»«ng khÃ¡ch hÃ ng

Client-side encryption Ä‘áº£m báº£o dá»¯ liá»‡u Ä‘Æ°á»£c mÃ£ hÃ³a ngay trong quÃ¡ trÃ¬nh xá»­ lÃ½

![img](https://static.cloudexam.pro/courses/5/1756914659523-53utru2r-CleanShot_2025-09-04_at_00.50.03.png)

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Create one AWS Glue job for each customer. Attach a security configuration to each job that uses server-side encryption with Amazon S3 managed keys (SSE-S3) to encrypt the data.

â†’ SSE-S3 chá»‰ mÃ£ hÃ³a khi lÆ°u trá»¯ á»Ÿ S3, khÃ´ng cho phÃ©p mÃ£ hÃ³a trong quÃ¡ trÃ¬nh náº¡p data vÃ  khÃ´ng sá»­ dá»¥ng customer-specific keys Ä‘Æ°á»£c

âŒ Create one Amazon EMR cluster for each customer. Attach a security configuration to each cluster that uses client-side encryption with a custom client-side root key (CSE-Custom) to encrypt the data.

â†’ EMR yÃªu cáº§u nhiá»u operational effort hÆ¡n Glue (do cháº¡y trÃªn EC2). HÆ¡n ná»¯a CSE-Custom phá»©c táº¡p hÆ¡n CSE-KMS

âŒ Create one Amazon EMR cluster for each customer. Attach a security configuration to each cluster that uses server-side encryption with AWS KMS keys (SSE-KMS) to encrypt the data.

â†’ EMR yÃªu cáº§u nhiá»u operational effort hÆ¡n Glue (do cháº¡y trÃªn EC2). HÆ¡n ná»¯a SSE-KMS chá»‰ mÃ£ hÃ³a táº¡i S3 lÃºc lÆ°u trá»¯, khÃ´ng mÃ£ hÃ³a trong quÃ¡ trÃ¬nh náº¡p data vÃ o S3

ğŸ”‘ Tips and tricks:

BÃ i toÃ¡n nháº¯c Ä‘áº¿n use case ETL (extract-transform-load) vÃ  yÃªu cáº§u tá»‘n Ã­t effort (LEAST operational effort) thÃ¬ thÆ°á»ng sáº½ nghÄ© Ä‘áº¿n AWS Glue

ğŸ“– Reference:

https://aws.amazon.com/blogs/storage/understanding-amazon-s3-client-side-encryption-options/#:~:text=Using%20client%2Dside%20encryption%20(CSE,keys%20used%20to%20encrypt%20objects.
</details>

---

### Q14. 
A company is creating a new web application for its subscribers. The application will consist of a static single page and a persistent database layer. The application will have millions of users for 4 hours in the morning, but the application will have only a few thousand users during the rest of the day. The company's data architects have requested the ability to rapidly evolve their schema.

Which solutions will meet these requirements and provide the MOST scalability? (Choose two.)
- Deploy the web servers for static content across a fleet of Amazon EC2 instances in Auto Scaling groups. Configure the instances to periodically refresh the content from an Amazon Elastic File System (Amazon EFS) volume.
- Deploy Amazon DynamoDB as the database solution. Provision on-demand capacity.
- Deploy Amazon Aurora as the database solution. Choose the serverless DB engine mode.
- Deploy Amazon DynamoDB as the database solution. Ensure that DynamoDB auto scaling is enabled.
- Deploy the static content into an Amazon S3 bucket. Provision an Amazon CloudFront distribution with the S3 bucket as the origin.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

á»¨ng dá»¥ng web cÃ³ host web tÄ©nh (static single page) vÃ  database

LÆ°u lÆ°á»£ng truy cáº­p khÃ´ng á»•n Ä‘á»‹nh: hÃ ng triá»‡u users truy cáº­p trong vÃ²ng 4h sÃ¡ng, chá»‰ vÃ i nghÃ¬n users truy cáº­p thá»i gian cÃ²n láº¡i

DB yÃªu cáº§u kháº£ nÄƒng linh hoáº¡t Ä‘Ã¡p á»©ng cÃ¡c thay Ä‘á»•i vá» schema (rapidly evolve schema)

Cáº§n giáº£i phÃ¡p cÃ³ kháº£ nÄƒng má»Ÿ rá»™ng tá»‘t (scalability) cho viá»‡c host web tÄ©nh vÃ  database

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Äá»‘i vá»›i database thÃ¬ sáº½ lá»±a chá»n Ä‘Ã¡p Ã¡n:

Deploy Amazon DynamoDB as the database solution. Provision on-demand capacity.

On-demand capacity lÃ  cÆ¡ cháº¿ traffic cá»§a DynamoDB cho phÃ©p tá»± Ä‘á»™ng scale theo traffic thá»±c táº¿, phÃ¹ há»£p vá»›i pattern lÆ°u lÆ°á»£ng khÃ´ng Ä‘á»u (triá»‡u users â†’ vÃ i nghÃ¬n users)

DynamoDB lÃ  NoSQL Databse nÃªn sáº½ há»— trá»£ schema linh hoáº¡t - cÃ³ thá»ƒ thay Ä‘á»•i schema nhanh chÃ³ng mÃ  khÃ´ng phÃ¡t sinh downtime

Äá»‘i vá»›i viá»‡c host web tÄ©nh thÃ¬ sáº½ lá»±a chá»n Ä‘Ã¡p Ã¡n:

Deploy the static content into an Amazon S3 bucket. Provision an Amazon CloudFront distribution with the S3 bucket as the origin.

S3 + CloudFront lÃ  giáº£i phÃ¡p tá»‘i Æ°u cho static content, scale khÃ´ng giá»›i háº¡n

CloudFront CDN Ä‘áº£m báº£o performance tá»‘t cho hÃ ng triá»‡u concurrent users

![img](https://static.cloudexam.pro/courses/5/1756974900934-cgvohw6i-image.png)

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Deploy Amazon Aurora as the database solution. Choose the serverless DB engine mode.

Tuy Aurora Serverless cÃ³ thá»ƒ auto-scale, nhÆ°ng Aurora lÃ  DB dáº¡ng quan há»‡ do Ä‘Ã³ khÃ´ng linh hoáº¡t trong viá»‡c thay Ä‘á»•i schema so vá»›i NoSQL DynamoDB

âŒ Deploy Amazon DynamoDB as the database solution. Ensure that DynamoDB auto scaling is enabled.

Auto Scaling sáº½ cáº§n chá» Cloudwatch Alarm kÃ­ch hoáº¡t khi traffic tÄƒng Ä‘á»™t biáº¿n, do Ä‘Ã³ khÃ´ng thá»ƒ scale ngay láº­p tá»©c Ä‘Æ°á»£c, sá»­ dá»¥ng on-demand capacity há»£p lÃ½ hÆ¡n

âŒ Deploy the web servers for static content across a fleet of Amazon EC2 instances in Auto Scaling groups. Configure the instances to periodically refresh the content from an Amazon Elastic File System (Amazon EFS) volume.

QuÃ¡ phá»©c táº¡p vÃ  khÃ´ng cost-effective cho static content. S3 + CloudFront Ä‘Æ¡n giáº£n vÃ  ráº» hÆ¡n nhiá»u

ğŸ”‘ Tips and tricks:

CÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n use case host web tÄ©nh thÃ¬ thÆ°á»ng sáº½ nghÄ© Ä‘áº¿n CloudFront vÃ  S3

Äá» bÃ i nháº¯c Ä‘áº¿n DB cÃ³ kháº£ nÄƒng linh hoáº¡t Ä‘Ã¡p á»©ng thay Ä‘á»•i schema (rapidly evolve schema) thÃ¬ sáº½ nghÄ© Ä‘áº¿n DynamoDB
</details>

---

### Q15
A company tracks customer satisfaction by using surveys that the company hosts on its website. The surveys sometimes reach thousands of customers every hour. Survey results are currently sent in email messages to the company so company employees can manually review results and assess customer sentiment.

The company wants to automate the customer survey process. Survey results must be available for the previous 12 months.

Which solution will meet these requirements in the MOST scalable way?
- Send the survey results data to an Amazon API Gateway endpoint that is connected to an Amazon Simple Queue Service (Amazon SQS) queue. Create an AWS Lambda function to poll the SQS queue, call Amazon Comprehend for sentiment analysis, and save the results to an Amazon DynamoDB table. Set the TTL for all records to 365 days in the future.
- Send the survey results data to an API that is running on an Amazon EC2 instance. Configure the API to store the survey results as a new record in an Amazon DynamoDB table, call Amazon Comprehend for sentiment analysis, and save the results in a second DynamoDB table. Set the TTL for all records to 365 days in the future
- Write the survey results data to an Amazon S3 bucket. Use S3 Event Notifications to invoke an AWS Lambda function to read the data and call Amazon Rekognition for sentiment analysis. Store the sentiment analysis results in a second S3 bucket. Use S3 lifecycle policies on each bucket to expire objects after 365 days.
- Send the survey results data to an Amazon API Gateway endpoint that is connected to an Amazon Simple Queue Service (Amazon SQS) queue. Configure the SQS queue to invoke an AWS Lambda function that calls Amazon Lex for sentiment analysis and saves the results to an Amazon DynamoDB table. Set the TTL for all records to 365 days in the future.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

CÃ´ng ty thu tháº­p kháº£o sÃ¡t khÃ¡ch hÃ ng (customer surveys) tá»« website

Káº¿t quáº£ kháº£o sÃ¡t hiá»‡n táº¡i Ä‘ang Ä‘Æ°á»£c nhÃ¢n viÃªn review thá»§ cÃ´ng

Cáº§n solution cÃ³ thá»ƒ má»Ÿ rá»™ng nháº¥t (MOST scalable) vÃ  Ä‘Ã¡p á»©ng yÃªu cáº§u:

Tá»± Ä‘á»™ng hoÃ¡ quÃ¡ trÃ¬nh kháº£o sÃ¡t

PhÃ¢n tÃ­ch thÃ¡i Ä‘á»™ ngÆ°á»i dÃ¹ng (sentiment analysis) tá»« káº¿t quáº£ kháº£o sÃ¡t

Data chá»‰ cáº§n lÆ°u trá»¯ 365 ngÃ y

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Send the survey results data to an Amazon API Gateway endpoint that is connected to an Amazon Simple Queue Service (Amazon SQS) queue. Create an AWS Lambda function to poll the SQS queue, call Amazon Comprehend for sentiment analysis, and save the results to an Amazon DynamoDB table. Set the TTL for all records to 365 days in the future.

API Gateway + SQS + Lambda + Comprehend + DynamoDB lÃ  kiáº¿n trÃºc serverless hoÃ n toÃ n, do Ä‘Ã³ sáº½ scale tá»‘t vÃ  Ä‘Ã¡p á»©ng yÃªu cáº§u:

API Gateway Ä‘Ã³ng vai trÃ² lÃ  API tiáº¿p nháº­n dá»¯ liá»‡u kháº£o sÃ¡t khÃ¡ch hÃ ng

SQS Ä‘áº£m báº£o khÃ´ng máº¥t dá»¯ liá»‡u khi cÃ³ traffic tÄƒng, cho phÃ©p decoupling giá»¯a cÃ¡c thÃ nh pháº§n Ä‘á»ƒ cÃ³ thá»ƒ scale Ä‘á»™c láº­p

Lambda cÃ³ thá»ƒ gá»i Amazon Comprehend lÃ  dá»‹ch vá»¥ chuyÃªn dá»¥ng cho sentiment analysis Ä‘á»ƒ thá»±c hiá»‡n phÃ¢n tÃ­ch thÃ¡i Ä‘á»™

Sau khi phÃ¢n tÃ­ch xong thÃ¬ data lÆ°u vÃ o DynamoDB, vá»›i chá»©c nÄƒng TTL thÃ¬ cÃ³ thá»ƒ tá»± Ä‘á»™ng xÃ³a data sau 365 ngÃ y

![img](https://static.cloudexam.pro/courses/5/1756915815849-hz16qitq-CleanShot_2025-09-04_at_01.09.45.png)

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Send the survey results data to an API that is running on an Amazon EC2 instance. Configure the API to store the survey results as a new record in an Amazon DynamoDB table, call Amazon Comprehend for sentiment analysis, and save the results in a second DynamoDB table. Set the TTL for all records to 365 days in the future

â†’ EC2 khÃ´ng tá»± Ä‘á»™ng scale nhÆ° serverless, cáº§n quáº£n lÃ½ infrastructure, kÃ©m scalable hÆ¡n

âŒ Write the survey results data to an Amazon S3 bucket. Use S3 Event Notifications to invoke an AWS Lambda function to read the data and call Amazon Rekognition for sentiment analysis. Store the sentiment analysis results in a second S3 bucket. Use S3 lifecycle policies on each bucket to expire objects after 365 days.

â†’ Amazon Rekognition dÃ¹ng cho phÃ¢n tÃ­ch image/video analysis, khÃ´ng pháº£i sentiment analysis

âŒ Send the survey results data to an Amazon API Gateway endpoint that is connected to an Amazon Simple Queue Service (Amazon SQS) queue. Configure the SQS queue to invoke an AWS Lambda function that calls Amazon Lex for sentiment analysis and saves the results to an Amazon DynamoDB table. Set the TTL for all records to 365 days in the future.

â†’ Amazon Lex dÃ¹ng cho chatbot/conversational AI, khÃ´ng chuyÃªn vá» sentiment analysis

ğŸ”‘ Tips and tricks:

PhÃ¢n tÃ­ch thÃ¡i Ä‘á»™ ngÆ°á»i dÃ¹ng (sentiment analysis) thÃ¬ thÆ°á»ng nghÄ© ngay Ä‘áº¿n Comprehend
</details>

---

### Q16. 
A company hosts its enterprise resource planning (ERP) system in the us-east-1 Region. The system runs on Amazon EC2 instances. Customers use a public API that is hosted on the EC2 instances to exchange information with the ERP system. International customers report slow API response times from their data centers.

Which solution will improve response times for the international customers MOST cost-effectively?
- Set up an Amazon CloudFront distribution in front of the API. Configured CachingOptimized managed cache policy to improved cache efficiency
- Set up AWS Global Accelerator. Configure listeners for the necessary ports. Configure endpoint groups for the appropriate Regions to distribute traffic. Create an endpoint in the group for the API.
- Create an AWS Direct Connect connection that has a public virtual interface (VIF)
- Use AWS Site-to-Site VPN to establish dedicated VPN tunnels

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

CÃ´ng ty cÃ³ há»‡ thá»‘ng ERP (enterprise resource planning) cháº¡y trÃªn EC2 á»Ÿ us-east-1

KhÃ¡ch hÃ ng sá»­ dá»¥ng public API Ä‘Æ°á»£c host trÃªn EC2 Ä‘á»ƒ trao Ä‘á»•i thÃ´ng tin

KhÃ¡ch hÃ ng quá»‘c táº¿ (international customers) bÃ¡o cÃ¡o thá»i gian pháº£n há»“i cháº­m (slow API response times)

Cáº§n giáº£i phÃ¡p cáº£i thiá»‡n response time mÃ  há»£p lÃ­ vá» máº·t chi phÃ­ (cost-effectively) nháº¥t

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Set up AWS Global Accelerator. Configure listeners for the necessary ports. Configure endpoint groups for the appropriate Regions to distribute traffic. Create an endpoint in the group for the API.

â†’ AWS Global Accelerator lÃ  giáº£i phÃ¡p giÃºp tÄƒng tá»‘c, cáº£i thiá»‡n hiá»‡u suáº¥t cho phÃ©p cÃ¡c káº¿t ná»‘i trÃªn kháº¯p tháº¿ giá»›i Ä‘áº¿n há»‡ thá»‘ng má»™t cÃ¡ch nhanh nháº¥t thÃ´ng qua máº¡ng lÆ°á»›i ná»™i bá»™ toÃ n cáº§u cá»§a AWS. Do Ä‘á»‹nh tuyáº¿n traffic qua Ä‘Æ°á»ng truyá»n tá»‘i Æ°u, giÃºp giáº£m Ä‘á»™ trá»… (latency) cho khÃ¡ch hÃ ng quá»‘c táº¿ mÃ  khÃ´ng cáº§n thay Ä‘á»•i kiáº¿n trÃºc hiá»‡n táº¡i.

![img](https://static.cloudexam.pro/courses/5/1756975990773-s5txd0h2-image.png)

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Create an AWS Direct Connect connection that has a public virtual interface (VIF)

â†’ Direct Connect yÃªu cáº§u physical connection táº¡i má»—i data center cá»§a khÃ¡ch hÃ ng, chi phÃ­ ráº¥t cao vÃ  phá»©c táº¡p Ä‘á»ƒ triá»ƒn khai cho nhiá»u khÃ¡ch hÃ ng quá»‘c táº¿.

âŒ Set up an Amazon CloudFront distribution in front of the API
â†’ CloudFront chá»§ yáº¿u tá»‘i Æ°u cho cache content tÄ©nh (static content caching) nhÆ° lÃ  file áº£nh, v.v.. API calls thÆ°á»ng lÃ  dynamic content do Ä‘Ã³ khÃ´ng cache Ä‘Æ°á»£c hiá»‡u quáº£, Ä‘áº·c biá»‡t lÃ  ERP system cáº§n real-time data.

âŒ Use AWS Site-to-Site VPN to establish dedicated VPN tunnels

â†’ Site-to-Site VPN dÃ¹ng Ä‘á»ƒ káº¿t ná»‘i mÃ´i trÆ°á»ng VPC vá»›i On-premise, khÃ´ng liÃªn quan Ä‘áº¿n viá»‡c Ä‘á»‹nh tuyáº¿n traffic cho ngÆ°á»i dÃ¹ng quá»‘c táº¿ á»Ÿ Ä‘Ã¢y.

ğŸ”‘ Tips and tricks:

CÃ¡c bÃ i toÃ¡n cáº§n tÄƒng tá»‘c káº¿t ná»‘i Ä‘áº¿n há»‡ thá»‘ng thÃ¬ thÆ°á»ng nghÄ© Ä‘áº¿n Global Accelerator
</details>

---

### Q17. 
A company runs its media rendering application on premises. The company wants to reduce storage costs and has moved all data to Amazon S3. The on-premises rendering application needs low-latency access to storage.

The company needs to design a storage solution for the application. The storage solution must maintain the desired application performance.

Which storage solution will meet these requirements in the MOST cost-effective way?
- Configure on-premises file server vá»›i S3 API. Configure the application to access the storage from the on-premises file server
- Copy data from Amazon S3 to Amazon FSx for Window File Server. Configure an Amazon FSx File Gateway to provide storage for the on-premises application
- Configure an Amazon S3 File Gateway to provide storage for the on-premises application.
- Use Mountpoint for Amazon S3 to access the data in Amazon S3

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

CÃ´ng ty cháº¡y á»©ng dá»¥ng á»Ÿ phÃ­a on-premises

ÄÃ£ chuyá»ƒn táº¥t cáº£ data lÃªn Amazon S3 Ä‘á»ƒ giáº£m chi phÃ­ storage

á»¨ng dá»¥ng on-premises cáº§n truy cáº­p Ä‘áº¿n storage vá»›i Ä‘á»™ trá»… tháº¥p (low-latency)

Cáº§n giáº£i phÃ¡p chi phÃ­ tháº¥p (cost-effective) nháº¥t mÃ  váº«n Ä‘áº£m báº£o performance (maintain performance)

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Configure an Amazon S3 File Gateway to provide storage for the on-premises application.

â†’ S3 File Gateway lÃ  giáº£i phÃ¡p tá»‘i Æ°u vÃ¬:

Cung cáº¥p NFS/SMB interface Ä‘á»ƒ á»©ng dá»¥ng on-premises cÃ³ thá»ƒ truy cáº­p S3 nhÆ° lÃ  local file system

CÃ³ local cache Ä‘á»ƒ Ä‘áº£m báº£o viá»‡c truy cáº­p vá»›i Ä‘á»™ trá»… tháº¥p (low-latency) cho data truy cáº­p thÆ°á»ng xuyÃªn (frequently accessed data)

![img](https://static.cloudexam.pro/courses/5/1756976738146-tjifir74-image.png)

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Use Mountpoint for Amazon S3 to access the data in Amazon S3

Mountpoint lÃ  tool cá»§a AWS cho phÃ©p access Ä‘áº¿n S3 trá»±c tiáº¿p nhÆ° lÃ  local file system. Tuy nhiÃªn chá»‰ há»— trá»£ Linux vÃ  váº«n chÆ°a phÃ¡t triá»ƒn, váº«n cÃ²n nhiá»u háº¡n cháº¿, do Ä‘Ã³ khÃ´ng phÃ¹ há»£p cho production-workload

KhÃ´ng cÃ³ local caching nhÆ° File Gateway â†’ performance khÃ´ng tá»‘i Æ°u

âŒ Copy data tá»« S3 sang Amazon FSx + FSx File Gateway

Tá»‘n kÃ©m do pháº£i Ä‘á»ƒ data á»Ÿ cáº£ 2 nÆ¡i, vÃ  pháº£i tráº£ thÃªm cho FSx storage, tÄƒng tÃ­nh phá»©c táº¡p khÃ´ng cáº§n thiáº¿t

âŒ Configure on-premises file server vá»›i S3 API

Phá»©c táº¡p, Ä‘á»ƒ lÃ m Ä‘Æ°á»£c viá»‡c nÃ y thÃ¬ cáº§n dev má»™t há»‡ thá»‘ng riÃªng

KhÃ´ng cÃ³ built-in caching vÃ  tá»‘i Æ°u hÃ³a nhÆ° File Gateway

ğŸ”‘ Tips and tricks:

Cáº§n solution vá» storage cho phÃ­a on-premise cho phÃ©p káº¿t ná»‘i vÃ  Ä‘á»“ng bá»™ lÃªn s3 thÃ¬ sáº½ nghÄ© Ä‘áº¿n S3 File Gateway
</details>

---

### Q18. 
An online gaming company is transitioning user data storage to Amazon DynamoDB to support the company's growing user base. The current architecture includes DynamoDB tables that contain user profiles, achievements, and in-game transactions.

The company needs to design a robust, continuously available, and resilient DynamoDB architecture to maintain a seamless gaming experience for users.

Which solution will meet these requirements MOST cost-effectively?
- A. MongoDB
- B. Redis
- C. MySQL
- Use DynamoDB global tables for automatic multi-Region replication. Deploy tables in multiple AWS Regions. Use provisioned capacity mode. Enable auto scaling.
- 
<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

CÃ´ng ty game cáº§n chuyá»ƒn dá»¯ liá»‡u user sang DynamoDB Ä‘á»ƒ Ä‘Ã¡p á»©ng sá»‘ lÆ°á»£ng ngÆ°á»i chÆ¡i tÄƒng lÃªn

Cáº§n thiáº¿t káº¿ kiáº¿n trÃºc tá»‘i Æ°u, cÃ³ tÃ­nh kháº£ dá»¥ng cao vÃ  kháº£ nÄƒng chá»‹u lá»—i tá»‘t (robust, continuously available, resilient)

YÃªu cáº§u MOST cost-effectively (tá»‘i Æ°u hiá»‡u quáº£ chi phÃ­ nháº¥t)

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Use DynamoDB global tables for automatic multi-Region replication. Deploy tables in multiple AWS Regions. Use provisioned capacity mode. Enable auto scaling.
â†’ Global tables cho phÃ©p cháº¡y DynamoDB trÃªn nhiá»u region, giÃºp Ä‘áº£m báº£o tÃ­nh kháº£ dá»¥ng cao vÃ  kháº£ nÄƒng chá»‹u lá»—i Ä‘á»“ng thá»i cÃ³ thá»ƒ phá»¥c vá»¥ Ä‘Æ°á»£c lÆ°á»£ng ngÆ°á»i dÃ¹ng trÃªn kháº¯p tháº¿ giá»›i tá»‘t hÆ¡n. Sá»­ dá»¥ng káº¿t há»£p vá»›i Provisioned capacity vá»›i auto scaling tá»‘i Æ°u chi phÃ­ hÆ¡n on-demand khi cÃ³ traffic á»•n Ä‘á»‹nh vÃ  cÃ³ thá»ƒ dá»± Ä‘oÃ¡n Ä‘Æ°á»£c.

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Create DynamoDB tables in a single AWS Region. Use on-demand capacity mode. Use global tables to replicate data across multiple Regions.

â†’ Sai logic. KhÃ´ng thá»ƒ dÃ¹ng global tables náº¿u chá»‰ táº¡o table á»Ÿ single Region. Global tables yÃªu cáº§u táº¡o table á»Ÿ nhiá»u Region.

âŒ Use DynamoDB Accelerator (DAX) to cache frequently accessed data. Deploy tables in a single AWS Region and enable auto scaling. Configure Cross-Region Replication manually to additional Regions.

â†’ Sá»­ dá»¥ng DAX sáº½ lÃ m tÄƒng nhiá»u chi phÃ­, hÆ¡n ná»¯a viá»‡c cháº¡y DynamoDB trÃªn 1 region vÃ  replicate data thá»§ cÃ´ng sang cÃ¡c region khÃ¡c sáº½ khÃ´ng hiá»‡u quáº£ do khÃ´ng cÃ³ tÃ­nh tá»± Ä‘á»™ng hÃ³a.

âŒ Create DynamoDB tables in multiple AWS Regions. Use on-demand capacity mode. Use DynamoDB Streams for Cross-Region Replication between Regions.

â†’ DynamoDB Streams + manual replication phá»©c táº¡p hÆ¡n so vá»›i viá»‡c dÃ¹ng trá»±c tiáº¿p global tables. HÆ¡n ná»¯a On-demand Ä‘áº¯t hÆ¡n provisioned.

ğŸ”‘ Tips and tricks:

Dynamo DB Ä‘á»ƒ cÃ³ tÃ­nh kháº£ dá»¥ng liÃªn tá»¥c, chá»‹u lá»—i tá»‘t thÃ¬ nghÄ© Ä‘áº¿n Global Table & Multi-Region deployment
</details>

---

### Q19. 
A company operates a food delivery service. Because of recent growth, the company's order processing system is experiencing scaling problems during peak traffic hours. The current architecture includes Amazon EC2 instances in an Auto Scaling group that collect orders from an application. A second group of EC2 instances in an Auto Scaling group fulfills the orders.

The order collection process occurs quickly, but the order fulfillment process can take longer. Data must not be lost because of a scaling event.

A solutions architect must ensure that the order collection process and the order fulfillment process can both scale adequately during peak traffic hours.

Which solution will meet these requirements?
- Provision two Amazon Simple Queue Service (Amazon SQS) queues. Use one SQS queue for order collection. Use the second SQS queue for order fulfillment. Configure the EC2 instances to poll their respective queues. Scale the Auto Scaling groups based on the number of messages in each queue.
- Use Amazon CloudWatch to monitor the CPUUtilization metric for each instance in both Auto Scaling groups. Configure each Auto Scaling group's minimum capacity to meet its peak workload value.
- Use Amazon CloudWatch to monitor the CPUUtilization metric for each instance in both Auto Scaling groups. Configure a CloudWatch alarm to invoke an Amazon Simple Notification Service (Amazon SNS) topic to create additional Auto Scaling groups on demand.
- Provision two Amazon Simple Queue Service (Amazon SQS) queues. Use one SQS queue for order collection. Use the second SQS queue for order fulfillment. Configure the EC2 instances to poll their respective queues. Scale the Auto Scaling groups based on notifications that the queues send.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

CÃ´ng ty giao Ä‘á»“ Äƒn gáº·p váº¥n Ä‘á» vá» kháº£ nÄƒng scale há»‡ thá»‘ng trong giá» cao Ä‘iá»ƒm

Kiáº¿n trÃºc hiá»‡n táº¡i: cÃ³ 2 nhÃ³m EC2 Auto Scaling

NhÃ³m 1: thu tháº­p Ä‘Æ¡n hÃ ng (order collection) - xá»­ lÃ½ nhanh

NhÃ³m 2: xá»­ lÃ½ Ä‘Æ¡n hÃ ng (order fulfillment) - xá»­ lÃ½ cháº­m hÆ¡n

YÃªu cáº§u: khÃ´ng Ä‘Æ°á»£c máº¥t dá»¯ liá»‡u (data must not be lost) khi scaling

Cáº§n giáº£i phÃ¡p cho cáº£ 2 process Ä‘á»u scale Ä‘Æ°á»£c trong peak traffic

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Provision two Amazon Simple Queue Service (Amazon SQS) queues. Use one SQS queue for order collection. Use the second SQS queue for order fulfillment. Configure the EC2 instances to poll their respective queues. Scale the Auto Scaling groups based on the number of messages in each queue.

Sá»­ dá»¥ng SQS queue Ä‘Ã³ng vai trÃ² buffer cho viá»‡c truyá»n data Ä‘áº¿n má»—i nhÃ³m EC2, tá»« Ä‘Ã³ giÃºp Ä‘áº£m báº£o khÃ´ng máº¥t data khi EC2 scale.

Äá»ƒ cÃ³ kháº£ nÄƒng scale EC2 tá»± Ä‘á»™ng khi traffic tÄƒng thÃ¬ sáº½ dá»±a vÃ o Metric sá»‘ lÆ°á»£ng messages trong queue thá»±c táº¿ Ä‘ang lÃ  bao nhiÃªu, tá»« Ä‘Ã³ Ä‘áº·t Cloudwatch Alarm phÃ¹ há»£p.

![img](https://static.cloudexam.pro/courses/5/1756977911129-d841wucm-image.png)

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Use Amazon CloudWatch to monitor the CPUUtilization metric for each instance in both Auto Scaling groups. Configure each Auto Scaling group's minimum capacity to meet its peak workload value.

Chá»‰ Ä‘áº·t minimum capacity khÃ´ng giáº£i quyáº¿t Ä‘Æ°á»£c váº¥n Ä‘á» data loss khi instance terminate Ä‘á»™t ngá»™t. CPU metric cÅ©ng khÃ´ng pháº£n Ã¡nh chÃ­nh xÃ¡c lÆ°á»£ng workload hiá»‡n táº¡i cá»§a queue.

âŒ Use Amazon CloudWatch to monitor the CPUUtilization metric for each instance in both Auto Scaling groups. Configure a CloudWatch alarm to invoke an Amazon Simple Notification Service (Amazon SNS) topic to create additional Auto Scaling groups on demand.

Táº¡o thÃªm Auto Scaling group má»›i lÃ  phá»©c táº¡p hÃ³a vÃ  khÃ´ng cáº§n thiáº¿t. HÆ¡n ná»¯a khÃ´ng dÃ¹ng queue thÃ¬ váº«n khÃ´ng giáº£i quyáº¿t Ä‘Æ°á»£c váº¥n Ä‘á» bá»‹ máº¥t data.

âŒ Provision two Amazon Simple Queue Service (Amazon SQS) queues. Use one SQS queue for order collection. Use the second SQS queue for order fulfillment. Configure the EC2 instances to poll their respective queues. Scale the Auto Scaling groups based on notifications that the queues send.

SQS khÃ´ng cÃ³ cÆ¡ cháº¿ send notifications Ä‘á»ƒ scale, Ä‘Ã¡p Ã¡n vÃ´ lÃ½.

ğŸ”‘ Tips and tricks:

CÃ¡c bÃ i toÃ¡n liÃªn quan Ä‘áº¿n xá»­ lÃ­ order, cáº§n trÃ¡nh viá»‡c máº¥t data Ä‘á»“ng thá»i cho kháº£ nÄƒng scale dá»±a theo sá»‘ order thá»±c táº¿ thÃ¬ sáº½ nghÄ© Ä‘áº¿n SQS
</details>

---

### Q20. 

A company currently stores 5 TB of data in on-premises block storage systems. The company's current storage solution provides limited space for additional data. The company runs applications on premises that must be able to retrieve frequently accessed data with low latency. The company requires a cloud-based storage solution.

Which solution will meet these requirements with the MOST operational efficiency?
- Use Amazon S3 File Gateway with SMB file system
- Use Volume Gateway with stored volumes
- Use an AWS Storage Gateway Volume Gateway with cached volumes as iSCSI targets.
- Use Tape Gateway with virtual tapes

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

CÃ´ng ty lÆ°u dá»¯ liá»‡u trÃªn block storage á»Ÿ phÃ­a on-premises

KhÃ´ng gian lÆ°u trá»¯ háº¡n cháº¿ nÃªn cáº§n giáº£i phÃ¡p lÆ°u trá»¯ cloud-based vá»›i hiá»‡u quáº£ váº­n hÃ nh cao nháº¥t (MOST operational efficiency)

á»¨ng dá»¥ng on-premises cáº§n truy xuáº¥t dá»¯ liá»‡u thÆ°á»ng xuyÃªn truy cáº­p (frequently accessed) vá»›i Ä‘á»™ trá»… tháº¥p (low latency)

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Use an AWS Storage Gateway Volume Gateway with cached volumes as iSCSI targets.

Cached volumes lÆ°u dá»¯ liá»‡u thÆ°á»ng xuyÃªn truy cáº­p táº¡i local cache â†’ Ä‘áº£m báº£o low latency

CÃ¡c dá»¯ liá»‡u cÃ²n láº¡i sáº½ Ä‘Æ°á»£c Ä‘á»“ng bá»™ vÃ  lÆ°u trá»¯ táº¡i Amazon S3, do Ä‘Ã³ cÃ³ kháº£ nÄƒng má»Ÿ rá»™ng khÃ´ng giá»›i háº¡n

TÆ°Æ¡ng thÃ­ch vá»›i block storage hiá»‡n táº¡i (iSCSI protocol)

CÃ³ Ä‘á»™ hiá»‡u quáº£ váº­n hÃ nh (operational efficiency) cao vÃ¬ tá»± Ä‘á»™ng hoÃ¡ viá»‡c quáº£n lÃ­ cache táº¡i local

![img](https://static.cloudexam.pro/courses/5/1756991188130-0brb4wc2-CleanShot_2025-09-04_at_22.05.39.png)

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Use Amazon S3 File Gateway with SMB file system

Äá» yÃªu cáº§u block storage, khÃ´ng pháº£i file storage. SMB lÃ  file-based protocol, khÃ´ng tÆ°Æ¡ng thÃ­ch vá»›i á»©ng dá»¥ng block storage hiá»‡n táº¡i.

âŒ Use Volume Gateway with stored volumes

Sai vÃ¬ stored volumes máº·c dÃ¹ cÃ³ Ä‘á»“ng bá»™ lÃªn S3 tuy nhiÃªn váº«n lÆ°u toÃ n bá»™ dá»¯ liá»‡u táº¡i on-premises â†’ khÃ´ng giáº£i quyáº¿t váº¥n Ä‘á» limited space.

âŒ Use Tape Gateway with virtual tapes

Sai vÃ¬ Tape Gateway dÃ¹ng cho use case lÃ  archival/backup, khÃ´ng pháº£i cho data hay Ä‘Æ°á»£c truy cáº­p vá»›i Ä‘á»™ trá»… tháº¥p.

ğŸ”‘ Tips and tricks:

Khi cáº§n solution storage cho local mÃ  support dáº¡ng block storage thÃ¬ sáº½ nghÄ© Ä‘áº¿n Volume Gateway. Keyword: iSCSI, Block Storage, Volume
</details>

---

### Q21. 
A company is creating a prototype of an ecommerce website on AWS. The website consists of an Application Load Balancer, an Auto Scaling group of Amazon EC2 instances for web servers, and an Amazon RDS for MySQL DB instance that runs with the Single-AZ configuration.

The website is slow to respond during searches of the product catalog. The product catalog is a group of tables in the MySQL database that the company does not update frequently. A solutions architect has determined that the CPU utilization on the DB instance is high when product catalog searches occur.

What should the solutions architect recommend to improve the performance of the website during searches of the product catalog?
- Implement an Amazon ElastiCache for Redis cluster to cache the product catalog. Use lazy loading to populate the cache.
- Migrate the product catalog to an Amazon Redshift database. Use the COPY command to load the product catalog tables.
- Add an additional scaling policy to the Auto Scaling group to launch additional EC2 instances when database response is slow.
- Turn on the Multi-AZ configuration for the DB instance. Configure the EC2 instances to throttle the product catalog queries that are sent to the database.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

Website gá»“m ALB + Auto Scaling EC2 + RDS MySQL Single-AZ

TÃ¬m kiáº¿m báº£ng product catalog trong db bá»‹ cháº­m dáº«n Ä‘áº¿n CPU cao

Product catalog lÃ  nhÃ³m báº£ng khÃ´ng update thÆ°á»ng xuyÃªn trong MySQL

Cáº§n cáº£i thiá»‡n performance khi search catalog

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Implement an Amazon ElastiCache for Redis cluster to cache the product catalog. Use lazy loading to populate the cache.

CÃ³ thá»ƒ tháº¥y Ä‘Æ°á»£c báº£ng product catalog má»—i khi query sáº½ gÃ¢y áº£nh hÆ°á»Ÿng performance cá»§a DB. Äá»ƒ trÃ¡nh viá»‡c nÃ y thÃ¬ cÃ³ thá»ƒ cache data hay Ä‘Æ°á»£c query ra cache riÃªng biá»‡t. HÆ¡n ná»¯a báº£ng nÃ y khÃ´ng update thÆ°á»ng xuyÃªn nÃªn viá»‡c sá»­ dá»¥ng cache sáº½ cÃ ng há»£p lÃ½ vÃ¬ data sáº½ lÃ¢u bá»‹ outdated.

Giáº£i phÃ¡p cache dÃ¹ng cho RDS & Aurora chÃ­nh lÃ  ElastiCache, giÃºp tá»‘i Æ°u cho dá»¯ liá»‡u Ä‘á»c nhiá»u, ghi Ã­t nhÆ° product catalog.

ElastiCache Redis giáº£m táº£i CPU cho RDS báº±ng cÃ¡ch tráº£ vá» data query tá»« memory thay vÃ¬ pháº£i query trá»±c tiáº¿p vÃ o database.

Lazy Caching lÃ  hÃ¬nh thá»©c sáº½ Æ°u tiÃªn query data tá»« cache, náº¿u khÃ´ng cÃ³ thÃ¬ sáº½ vÃ o DB Ä‘á»ƒ láº¥y sau Ä‘Ã³ Ä‘Æ°a láº¡i vÃ o cache, Ä‘á»ƒ tá»« cÃ¡c request láº§n sau sáº½ cÃ³ data sáºµn sÃ ng trong cache Ä‘á»ƒ tráº£ vá» luÃ´n.

![img](https://static.cloudexam.pro/courses/5/1756992142856-eq3tglsx-image.png)


CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Migrate the product catalog to an Amazon Redshift database. Use the COPY command to load the product catalog tables.

â†’ Redshift dÃ nh cho data warehousing/analytics & bigdata, khÃ´ng phÃ¹ há»£p cho use case á»Ÿ Ä‘Ã¢y.

âŒ Add an additional scaling policy to the Auto Scaling group to launch additional EC2 instances when database response is slow.
â†’ Váº¥n Ä‘á» náº±m á»Ÿ database bottleneck, khÃ´ng pháº£i á»Ÿ phÃ­a web server. Scale thÃªm EC2 chá»‰ táº¡o thÃªm connection Ä‘áº¿n database, lÃ m tÃ¬nh tráº¡ng tá»‡ hÆ¡n.

âŒ Turn on the Multi-AZ configuration for the DB instance. Configure the EC2 instances to throttle the product catalog queries that are sent to the database.

â†’ Multi-AZ chá»‰ cáº£i thiá»‡n tÃ­nh kháº£ dá»¥ng (availability) cho DB chá»© khÃ´ng giÃºp cáº£i thiá»‡n performance.

ğŸ”‘ Tips and tricks:

Vá»›i cÃ¡c bÃ i toÃ¡n dÃ¹ng DB dáº¡ng quan há»‡ mÃ  data Ä‘á»c nhiá»u, ghi Ã­t thÃ¬ cÃ³ thá»ƒ sá»­ dá»¥ng ElastiCache Ä‘á»ƒ cache data
</details>

---

### Q22. 
A company runs its legacy web application on AWS. The web application server runs on an Amazon EC2 instance in the public subnet of a VPC. The web application server collects images from customers and stores the image files in a locally attached Amazon Elastic Block Store (Amazon EBS) volume. The image files are uploaded every night to an Amazon S3 bucket for backup.

A solutions architect discovers that the image files are being uploaded to Amazon S3 through the public endpoint. The solutions architect needs to ensure that traffic to Amazon S3 does not use the public endpoint.

Which solution will meet these requirements?
- Move the S3 bucket inside the VPC. Configure the subnet route table to access the S3 bucket through private IP addresses.
- Create an Amazon S3 access point for the Amazon EC2 instance inside the VPC. Configure the web application to upload by using the Amazon S3 access point.
- Configure an AWS Direct Connect connection between the VPC that has the Amazon EC2 instance and Amazon S3 to provide a dedicated network path.
- Create a gateway VPC endpoint for the S3 bucket that has the necessary permissions for the VPC. Configure the subnet route table to use the gateway VPC endpoint.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

Web application cháº¡y trÃªn EC2 trong public subnet

Upload image files lÃªn S3 bucket má»—i Ä‘Ãªm Ä‘á»ƒ backup

Hiá»‡n táº¡i traffic Ä‘áº¿n S3 Ä‘ang Ä‘i qua public endpoint (tá»©c lÃ  Ä‘i qua internet)

YÃªu cáº§u: Ä‘áº£m báº£o traffic Ä‘áº¿n S3 khÃ´ng sá»­ dá»¥ng public endpoint

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Create a gateway VPC endpoint for the S3 bucket that has the necessary permissions for the VPC. Configure the subnet route table to use the gateway VPC endpoint.

Gateway VPC Endpoint cho S3 lÃ  giáº£i phÃ¡p miá»…n phÃ­ Ä‘á»ƒ Ä‘á»‹nh tuyáº¿n traffic tá»« EC2 Ä‘áº¿n S3 qua máº¡ng ná»™i bá»™ AWS thay vÃ¬ internet. Route table sáº½ tá»± Ä‘á»™ng Ä‘á»‹nh tuyáº¿n traffic S3 qua endpoint nÃ y.

![img](https://static.cloudexam.pro/courses/5/1756992628593-gn6vdx1v-image.png)

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Move the S3 bucket inside the VPC. Configure the subnet route table to access the S3 bucket through private IP addresses.

â†’ VÃ´ lÃ½ vÃ¬ S3 lÃ  managed service, khÃ´ng thá»ƒ di chuyá»ƒn vÃ o trong VPC. S3 bucket luÃ´n náº±m ngoÃ i VPC.

âŒ Create an Amazon S3 access point for the Amazon EC2 instance inside the VPC. Configure the web application to upload by using the Amazon S3 access point.

â†’ S3 Access Point chá»‰ lÃ  cÃ¡ch thá»©c Ä‘á»ƒ táº¡o ra cÃ¡c Ä‘iá»ƒm truy cáº­p Ä‘áº¿n S3 phá»¥c vá»¥ cÃ¡c má»¥c Ä‘Ã­ch vÃ  quáº£n lÃ½ quyá»n truy cáº­p khÃ¡c nhau, khÃ´ng giÃºp thay Ä‘á»•i Ä‘Æ°á»ng Ä‘i cá»§a traffic. Traffic váº«n cÃ³ thá»ƒ Ä‘i qua public endpoint.

âŒ Configure an AWS Direct Connect connection between the VPC that has the Amazon EC2 instance and Amazon S3 to provide a dedicated network path.

â†’ Sai vÃ  khÃ´ng cáº§n thiáº¿t. Direct Connect dÃ¹ng cho káº¿t ná»‘i tá»« on-premises Ä‘áº¿n mÃ´i trÆ°á»ng VPC, khÃ´ng pháº£i cho traffic EC2-to-S3 trong cÃ¹ng region.

ğŸ”‘ Tips and tricks:

Cho phÃ©p application trong VPC access Ä‘áº¿n cÃ¡c service khÃ¡c má»™t cÃ¡ch an toÃ n, khÃ´ng Ä‘i qua internet thÃ¬ nghÄ© Ä‘áº¿n VPC Endpoint
</details>

---

### Q23. 
A company is launching a new application that requires a structured database to store user profiles, application settings, and transactional data. The database must be scalable with application traffic and must offer backups.

Which solution will meet these requirements MOST cost-effectively?
- Deploy a self-managed database on Amazon EC2 instances by using open source software. Use Spot Instances for cost optimization.
- Use Amazon RDS. Use on-demand capacity mode for the database with General Purpose SSD storage. Configure automatic backups with a retention period of 7 days.
- Use Amazon Aurora Serverless for the database. Use serverless capacity scaling. Configure automated backups to Amazon S3.
- Deploy a self-managed NoSQL database on Amazon EC2 instances. Use Reserved Instances for cost optimization. Configure automated backups directly to Amazon S3 Glacier Flexible Retrieval.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

CÃ´ng ty cáº§n cÆ¡ sá»Ÿ dá»¯ liá»‡u cÃ³ cáº¥u trÃºc (structured database) cho user profiles, settings, transactional data

YÃªu cáº§u: kháº£ nÄƒng scale theo traffic vÃ  cÃ³ backup tá»± Ä‘á»™ng

Má»¥c tiÃªu: tá»‘i Æ°u chi phÃ­ nháº¥t (MOST cost-effectively)

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Use Amazon Aurora Serverless for the database. Use serverless capacity scaling. Configure automated backups to Amazon S3.

Aurora Serverless lÃ  managed service cho phÃ©p táº¡o database dáº¡ng quan há»‡ (relational), cÃ³ cáº¥u trÃºc (structured) dÆ°á»›i dáº¡ng serverless, tá»« Ä‘Ã³ cÃ³ kháº£ nÄƒng scale tá»± Ä‘á»™ng Ä‘á»ƒ Ä‘Ã¡p á»©ng traffic, cÃ³ cÆ¡ cháº¿ backup Ä‘á»‹nh kÃ¬.

Vá»›i use case phá»• thÃ´ng thÃ¬ sá»­ dá»¥ng General Purpose SSD Ä‘á»ƒ tiáº¿t kiá»‡m chi phÃ­.

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Deploy a self-managed database on Amazon EC2 instances by using open source software. Use Spot Instances for cost optimization.

â†’ Deploy DB trÃªn EC2 lÃ m tÄƒng operational overhead, hÆ¡n ná»¯a Spot Instances khÃ´ng á»•n Ä‘á»‹nh cho viá»‡c cháº¡y database production.

âŒ Use Amazon RDS. Use on-demand capacity mode for the database with General Purpose SSD storage. Configure automatic backups with a retention period of 7 days.

â†’ RDS on-demand luÃ´n cháº¡y vÃ  tÃ­nh phÃ­ 24/7, hÆ¡n ná»¯a khÃ´ng cÃ³ kháº£ nÄƒng scale Ä‘á»ƒ Ä‘Ã¡p á»©ng traffic.

âŒ Deploy a self-managed NoSQL database on Amazon EC2 instances. Use Reserved Instances for cost optimization. Configure automated backups directly to Amazon S3 Glacier Flexible Retrieval.

â†’ Äá» yÃªu cáº§u DB dáº¡ng data cÃ³ cáº¥u trÃºc structured database (SQL), khÃ´ng pháº£i NoSQL.

ğŸ”‘ Tips and tricks:

DB dáº¡ng quan há»‡ cÃ³ kháº£ nÄƒng tá»± scale Ä‘á»ƒ Ä‘Ã¡p á»©ng traffic thÃ¬ nghÄ© Ä‘áº¿n Aurora Serverless
</details>

---

### Q24. 
A company runs an on-premises application on a Kubernetes cluster. The company recently added millions of new customers. The company's existing on-premises infrastructure is unable to handle the large number of new customers. The company needs to migrate the on-premises application to the AWS Cloud.

The company will migrate to an Amazon Elastic Kubernetes Service (Amazon EKS) cluster. The company does not want to manage the underlying compute infrastructure for the new architecture on AWS.

Which solution will meet these requirements with the LEAST operational overhead?
- Use a self-managed node to supply compute capacity
- Use managed node groups to supply compute capacity
- Use managed node groups with Karpenter to supply compute capacity
- Use AWS Fargate to supply compute capacity. Create a Fargate profile. Use the Fargate profile to deploy the application.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

CÃ´ng ty cháº¡y á»©ng dá»¥ng Kubernetes cluster on-premises

ThÃªm hÃ ng triá»‡u khÃ¡ch hÃ ng má»›i â†’ háº¡ táº§ng hiá»‡n táº¡i khÃ´ng Ä‘á»§ Ä‘Ã¡p á»©ng

Cáº§n migrate sang Amazon EKS

KhÃ´ng muá»‘n quáº£n lÃ½ (does not want to manage) háº¡ táº§ng

YÃªu cáº§u operational overhead tháº¥p nháº¥t (LEAST operational overhead)

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Use AWS Fargate to supply compute capacity. Create a Fargate profile. Use the Fargate profile to deploy the application.

Fargate lÃ  dá»‹ch vá»¥ serverless compute, Ä‘Æ°á»£c quáº£n lÃ½ vÃ  váº­n hÃ nh hoÃ n toÃ n bá»Ÿi AWS. KhÃ´ng cáº§n quáº£n lÃ½ nodes, patching, scaling infrastructure.

Chá»‰ cáº§n táº¡o Fargate profile vÃ  deploy pods, AWS sáº½ lo toÃ n bá»™ viá»‡c váº­n hÃ nh kiáº¿n trÃºc bÃªn dÆ°á»›i.

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Use a self-managed node to supply compute capacity

â†’ Self-managed nodes yÃªu cáº§u quáº£n lÃ½ toÃ n bá»™ EC2 instances, patching OS, scaling manually â†’ operational overhead cao nháº¥t.

âŒ Use managed node groups to supply compute capacity

â†’ Managed node groups váº«n cáº§n quáº£n lÃ½ node scaling, instance types, AMI updates â†’ váº«n cháº¡y trÃªn ná»n EC2 nÃªn cÃ³ operational overhead.

âŒ Use managed node groups with Karpenter to supply compute capacity

â†’ Karpenter giÃºp auto-scaling tá»‘t hÆ¡n nhÆ°ng váº«n cáº§n quáº£n lÃ½ nodes vÃ  configure Karpenter â†’ váº«n tá»‘n operational overhead.

ğŸ”‘ Tips and tricks:

CÃ¡c cÃ¢u há»i yÃªu cáº§u operational overhead tháº¥p nháº¥t (LEAST operational overhead) thÃ¬ thÆ°á»ng sáº½ nghÄ© Ä‘áº¿n cÃ¡c service serverless, Ä‘á»‘i vá»›i container thÃ¬ Ä‘Ã³ lÃ  AWS Fargate
</details>

---

### Q25. 
A company has migrated an application to Amazon EC2 Linux instances. One of these EC2 instances runs several 1-hour tasks on a schedule. These tasks were written by different teams and have no common programming language. The company is concerned about performance and scalability while these tasks run on a single instance. A solutions architect needs to implement a solution to resolve these concerns.

Which solution will meet these requirements with the LEAST operational overhead?
- Copy the tasks into AWS Lambda functions. Schedule the Lambda functions by using Amazon EventBridge (Amazon CloudWatch Events).
- Use AWS Batch to run the tasks as jobs. Schedule the jobs by using Amazon EventBridge (Amazon CloudWatch Events).
- Convert the EC2 instance to a container. Use AWS App Runner to create the container on demand to run the tasks as jobs.
- Create an Amazon Machine Image (AMI) of the EC2 instance that runs the tasks. Create an Auto Scaling group with the AMI to run multiple copies of the instance.

<details>
<summary>Answer</summary>
ğŸ“ TÃ³m táº¯t Ä‘á»:

CÃ´ng ty cáº§n cháº¡y job xá»­ lÃ½ video

Thá»i gian xá»­ lÃ½: lÃªn Ä‘áº¿n 20 phÃºt

Cáº§n giáº£i phÃ¡p scale tá»± Ä‘á»™ng vÃ  chi phÃ­ tiáº¿t kiá»‡m (cost-effective)

âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:

Use AWS Batch to run the tasks as jobs. Schedule the jobs by using Amazon EventBridge (Amazon CloudWatch Events).

AWS Batch lÃ  managed service Ä‘Æ°á»£c thiáº¿t káº¿ chuyÃªn cho batch computing workloads

Tá»± Ä‘á»™ng scale compute resources dá»±a trÃªn job queue

CÃ³ support trigger vá»›i EventBridge Ä‘á»ƒ schedule lá»‹ch cháº¡y job

LEAST operational overhead vÃ¬ AWS Batch lo toÃ n bá»™ viá»‡c quáº£n lÃ½ vÃ  scale cÃ¡c resource

CÃ¡c Ä‘Ã¡p Ã¡n sai:

âŒ Copy the tasks into AWS Lambda functions. Schedule the Lambda functions by using Amazon EventBridge (Amazon CloudWatch Events).

Lambda cÃ³ timeout tá»‘i Ä‘a 15 phÃºt, ko Ä‘Ã¡p á»©ng yÃªu cáº§u task cháº¡y 1 giá»

âŒ Convert the EC2 instance to a container. Use AWS App Runner to create the container on demand to run the tasks as jobs.

App Runner chá»§ yáº¿u dÃ¹ng cho web applications vÃ  APIs (long-running services), khÃ´ng phÃ¹ há»£p cho viá»‡c cháº¡y scheduled batch jobs

âŒ Create an Amazon Machine Image (AMI) of the EC2 instance that runs the tasks. Create an Auto Scaling group with the AMI to run multiple copies of the instance.

Váº«n pháº£i quáº£n lÃ½ EC2 instances â†’ operational overhead cao

ğŸ”‘ Tips and tricks:

Äá»‘i vá»›i cÃ¡c cÃ¢u há»i vá» viá»‡c cháº¡y job thÃ¬ cÃ¡c solution thÆ°á»ng nghÄ© Ä‘áº¿n Ä‘Ã³ lÃ  AWS Lambda, ECS Fargate, Batch, EC2 Spot Instances.

Äáº§u tiÃªn cáº§n xem thá»i gian cháº¡y job lÃ  bao lÃ¢u, náº¿u trÃªn 15 phÃºt sáº½ loáº¡i ngay Lambda, Æ°u tiÃªn chá»n cÃ¡c solution managed, serverless nhÆ° ECS Fargate, Batch.

Náº¿u thá»i gian dÆ°á»›i 15 phÃºt thÃ¬ thÆ°á»ng sáº½ lá»±a chá»n Lambda
</details>

---

### Q26. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q27. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q28. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q29. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q30. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q31. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q32. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q30. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q31. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q32. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q33. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q34. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q35. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q36. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q37. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q38. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q39. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q40. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q41. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q42. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q43. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>

---

### Q44. Which is not a NoSQL DB?
- A. MongoDB
- B. Redis
- C. MySQL
- D. Cassandra

<details>
<summary>Answer</summary>
C
</details>